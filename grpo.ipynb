{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f62cca2",
   "metadata": {},
   "source": [
    "# GRPO Zero Minimum Implementation\n",
    "\n",
    "This python notebook contains a full implementation of GRPO zero.\n",
    "\n",
    "## Quick Start\n",
    "\n",
    "### Environment Setup\n",
    "\n",
    "```bash\n",
    "conda env create -f environment.yml\n",
    "conda activate grpo-zero\n",
    "```\n",
    "\n",
    "### Download Dataset and Pre-trained Model\n",
    "\n",
    "```bash\n",
    "git clone https://huggingface.co/datasets/Jiayi-Pan/Countdown-Tasks-3to4\n",
    "git clone https://huggingface.co/Qwen/Qwen2.5-3B-Instruct\n",
    "```\n",
    "\n",
    "Then you can run all the code cells and start training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16211085",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "import gc\n",
    "import math\n",
    "import torch\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import yaml\n",
    "import time\n",
    "import html\n",
    "from datetime import datetime\n",
    "\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from collections import defaultdict\n",
    "from typing import Callable, List, Optional, Tuple, Union, Any, Dict\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset\n",
    "from jinja2 import Environment\n",
    "from tokenizers import Encoding\n",
    "from tokenizers import Tokenizer as TokenizerBase\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e10a93",
   "metadata": {},
   "source": [
    "Define the optimizer, the tokenizer and the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe5adba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MemoryEfficientAdamW(AdamW):\n",
    "    \"\"\"\n",
    "    Memory Efficient AdamW optimizer that keeps parameters and gradients on GPU\n",
    "    but optimizer states on CPU when enabled.\n",
    "    When disabled, behaves exactly like standard AdamW.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        params,\n",
    "        lr=1e-3,\n",
    "        betas=(0.9, 0.999),\n",
    "        eps=1e-8,\n",
    "        weight_decay=1e-2,\n",
    "        amsgrad=False,\n",
    "        pin_memory=True,\n",
    "        enabled=True,\n",
    "    ):\n",
    "        super(MemoryEfficientAdamW, self).__init__(\n",
    "            params,\n",
    "            lr=lr,\n",
    "            betas=betas,\n",
    "            eps=eps,\n",
    "            weight_decay=weight_decay,\n",
    "            amsgrad=amsgrad,\n",
    "        )\n",
    "        self.pin_memory = pin_memory\n",
    "        self.enabled = enabled\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, closure=None):\n",
    "        \"\"\"Performs a single optimization step.\"\"\"\n",
    "        if not self.enabled:\n",
    "            # Use the parent AdamW implementation when disabled\n",
    "            return super(MemoryEfficientAdamW, self).step(closure)\n",
    "\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            with torch.enable_grad():\n",
    "                loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            params_with_grad = []\n",
    "            grads = []\n",
    "            exp_avgs = []\n",
    "            exp_avg_sqs = []\n",
    "            max_exp_avg_sqs = []\n",
    "            state_steps = []\n",
    "            beta1, beta2 = group[\"betas\"]\n",
    "\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "\n",
    "                params_with_grad.append(p)\n",
    "                grads.append(p.grad)\n",
    "\n",
    "                # Initialize state if needed\n",
    "                state = self.state[p]\n",
    "                if len(state) == 0:\n",
    "                    state[\"step\"] = 0\n",
    "                    # Store optimizer states on CPU with pinned memory\n",
    "                    device = \"cpu\"\n",
    "                    pin_memory = self.pin_memory\n",
    "                    dtype = torch.float32\n",
    "\n",
    "                    state[\"exp_avg\"] = torch.zeros_like(\n",
    "                        p.data, device=device, pin_memory=pin_memory, dtype=dtype\n",
    "                    )\n",
    "                    state[\"exp_avg_sq\"] = torch.zeros_like(\n",
    "                        p.data, device=device, pin_memory=pin_memory, dtype=dtype\n",
    "                    )\n",
    "                    if group[\"amsgrad\"]:\n",
    "                        state[\"max_exp_avg_sq\"] = torch.zeros_like(\n",
    "                            p.data, device=device, pin_memory=pin_memory, dtype=dtype\n",
    "                        )\n",
    "\n",
    "                # Get state values\n",
    "                exp_avgs.append(state[\"exp_avg\"])\n",
    "                exp_avg_sqs.append(state[\"exp_avg_sq\"])\n",
    "\n",
    "                if group[\"amsgrad\"]:\n",
    "                    max_exp_avg_sqs.append(state[\"max_exp_avg_sq\"])\n",
    "\n",
    "                state[\"step\"] += 1\n",
    "                state_steps.append(state[\"step\"])\n",
    "\n",
    "            # Process all parameters in the group\n",
    "            self._memory_efficient_update(\n",
    "                params_with_grad,\n",
    "                grads,\n",
    "                exp_avgs,\n",
    "                exp_avg_sqs,\n",
    "                max_exp_avg_sqs,\n",
    "                state_steps,\n",
    "                amsgrad=group[\"amsgrad\"],\n",
    "                beta1=beta1,\n",
    "                beta2=beta2,\n",
    "                lr=group[\"lr\"],\n",
    "                weight_decay=group[\"weight_decay\"],\n",
    "                eps=group[\"eps\"],\n",
    "            )\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def _memory_efficient_update(\n",
    "        self,\n",
    "        params,\n",
    "        grads,\n",
    "        exp_avgs,\n",
    "        exp_avg_sqs,\n",
    "        max_exp_avg_sqs,\n",
    "        state_steps,\n",
    "        amsgrad,\n",
    "        beta1,\n",
    "        beta2,\n",
    "        lr,\n",
    "        weight_decay,\n",
    "        eps,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Performs the AdamW parameter update on GPU with CPU-stored optimizer states.\n",
    "        Uses pinned memory for efficient CPU-to-GPU transfer of optimizer states.\n",
    "        \"\"\"\n",
    "        for i, param in enumerate(params):\n",
    "            grad = grads[i]\n",
    "            param_device = param.device\n",
    "\n",
    "            # Access optimizer states - they'll transfer efficiently due to pin_memory\n",
    "            exp_avg = exp_avgs[i].to(param_device, non_blocking=True)\n",
    "            exp_avg_sq = exp_avg_sqs[i].to(param_device, non_blocking=True)\n",
    "\n",
    "            step = state_steps[i]\n",
    "\n",
    "            # Decay the first and second moment running averages\n",
    "            exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n",
    "            exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=1 - beta2)\n",
    "\n",
    "            if amsgrad:\n",
    "                # Access max_exp_avg_sq - transfers efficiently with pin_memory\n",
    "                max_exp_avg_sq = max_exp_avg_sqs[i].to(param_device, non_blocking=True)\n",
    "                # Maintains the maximum of all 2nd moment running avg. till now\n",
    "                torch.maximum(max_exp_avg_sq, exp_avg_sq, out=max_exp_avg_sq)\n",
    "                # Use the max for normalizing running avg of gradient\n",
    "                denom = max_exp_avg_sq.sqrt().add_(eps)\n",
    "                # Store back to CPU\n",
    "                max_exp_avg_sqs[i].copy_(max_exp_avg_sq, non_blocking=True)\n",
    "            else:\n",
    "                denom = exp_avg_sq.sqrt().add_(eps)\n",
    "\n",
    "            bias_correction1 = 1 - beta1**step\n",
    "            bias_correction2 = 1 - beta2**step\n",
    "            step_size = lr * math.sqrt(bias_correction2) / bias_correction1\n",
    "\n",
    "            # Apply weight decay directly to the parameter (AdamW)\n",
    "            if weight_decay != 0:\n",
    "                param.mul_(1 - lr * weight_decay)\n",
    "\n",
    "            # Update parameters (directly on GPU)\n",
    "            param.addcdiv_(exp_avg, denom, value=-step_size)\n",
    "\n",
    "            # Store optimizer states back to CPU\n",
    "            exp_avgs[i].copy_(exp_avg, non_blocking=True)\n",
    "            exp_avg_sqs[i].copy_(exp_avg_sq, non_blocking=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f08c55a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    \"\"\"Tokenizer with chat template supported using jinja2 engine\"\"\"\n",
    "\n",
    "    def __init__(self, tokenizer_path: str):\n",
    "        super().__init__()\n",
    "        tokenizer_config_path = Path(tokenizer_path).parent / \"tokenizer_config.json\"\n",
    "        self.tokenizer_config = json.load(open(tokenizer_config_path))\n",
    "        self.tokenizer = TokenizerBase.from_file(tokenizer_path)\n",
    "        self.chat_template = Environment().from_string(\n",
    "            self.tokenizer_config[\"chat_template\"]\n",
    "        )\n",
    "        self.eos_token = self.tokenizer_config[\"eos_token\"]\n",
    "        self.eos_token_id = self.tokenizer.token_to_id(self.eos_token)\n",
    "        self.pad_token = self.tokenizer_config[\"pad_token\"]\n",
    "        self.pad_token_id = self.tokenizer.token_to_id(self.pad_token)\n",
    "\n",
    "    def encode_chat(self, messages: List[Dict[str, str]]) -> str:\n",
    "        return self.chat_template.render(messages=messages, add_generation_prompt=True)\n",
    "\n",
    "    def encode_chat_with_response_prompt(\n",
    "        self, messages: List[Dict[str, str]], prompt: str\n",
    "    ) -> str:\n",
    "        return self.encode_chat(messages) + prompt\n",
    "\n",
    "    def tokenize(self, text: str) -> Encoding:\n",
    "        return self.tokenizer.encode(text)\n",
    "\n",
    "    def detokenize(self, token_ids: List[int]) -> str:\n",
    "        return self.tokenizer.decode(token_ids, skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71faf0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class Qwen2Config:\n",
    "    attention_dropout: float = 0.0\n",
    "    bos_token_id: int = 151643\n",
    "    eos_token_id: int = 151645\n",
    "    hidden_act: str = \"silu\"\n",
    "    hidden_size: int = 2048\n",
    "    initializer_range: float = 0.02\n",
    "    intermediate_size: int = 11008\n",
    "    max_position_embeddings: int = 32768\n",
    "    max_window_layers: int = 70\n",
    "    model_type: str = \"qwen2\"\n",
    "    num_attention_heads: int = 16\n",
    "    num_hidden_layers: int = 36\n",
    "    num_key_value_heads: int = 2\n",
    "    rms_norm_eps: float = 1e-06\n",
    "    rope_theta: float = 1000000.0\n",
    "    sliding_window: int = 32768\n",
    "    tie_word_embeddings: bool = True\n",
    "    torch_dtype: str = \"bfloat16\"\n",
    "    use_cache: bool = True\n",
    "    use_sliding_window: bool = False\n",
    "    vocab_size: int = 151936\n",
    "\n",
    "\n",
    "class RMSNorm(torch.nn.Module):\n",
    "    def __init__(self, dim: int, eps: float = 1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "\n",
    "    def _norm(self, x):\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_dtype = x.dtype\n",
    "        x = x.to(torch.float32)\n",
    "        x = self._norm(x).type_as(x)\n",
    "        x = self.weight * x.to(input_dtype)\n",
    "        return x\n",
    "\n",
    "\n",
    "def rotate_half(x):\n",
    "    \"\"\"Rotates half the hidden dims of the input.\"\"\"\n",
    "    x1 = x[..., : x.shape[-1] // 2]\n",
    "    x2 = x[..., x.shape[-1] // 2 :]\n",
    "    return torch.cat((-x2, x1), dim=-1)\n",
    "\n",
    "\n",
    "def apply_rotary_pos_emb(q, k, cos, sin, unsqueeze_dim=2):\n",
    "    cos = cos.unsqueeze(unsqueeze_dim)\n",
    "    sin = sin.unsqueeze(unsqueeze_dim)\n",
    "    q_embed = (q * cos) + (rotate_half(q) * sin)\n",
    "    k_embed = (k * cos) + (rotate_half(k) * sin)\n",
    "    return q_embed, k_embed\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, args: Qwen2Config):\n",
    "        super().__init__()\n",
    "        self.n_kv_heads = (\n",
    "            args.num_attention_heads\n",
    "            if args.num_key_value_heads is None\n",
    "            else args.num_key_value_heads\n",
    "        )\n",
    "        self.n_heads = args.num_attention_heads\n",
    "        self.n_kv_heads = self.n_kv_heads\n",
    "        self.n_rep = self.n_heads // self.n_kv_heads\n",
    "        self.head_dim = args.hidden_size // args.num_attention_heads\n",
    "\n",
    "        self.q_proj = nn.Linear(\n",
    "            args.hidden_size,\n",
    "            args.num_attention_heads * self.head_dim,\n",
    "            bias=True,\n",
    "        )\n",
    "        self.k_proj = nn.Linear(\n",
    "            args.hidden_size,\n",
    "            args.num_key_value_heads * self.head_dim,\n",
    "            bias=True,\n",
    "        )\n",
    "        self.v_proj = nn.Linear(\n",
    "            args.hidden_size,\n",
    "            args.num_key_value_heads * self.head_dim,\n",
    "            bias=True,\n",
    "        )\n",
    "        self.o_proj = nn.Linear(\n",
    "            args.num_attention_heads * self.head_dim,\n",
    "            args.hidden_size,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.args = args\n",
    "\n",
    "    def init_kv_cache(\n",
    "        self,\n",
    "        max_batch_size: int,\n",
    "        max_seq_len: int,\n",
    "        dtype: torch.dtype,\n",
    "        device: torch.device,\n",
    "    ):\n",
    "        cache_shape = (max_batch_size, max_seq_len, self.n_kv_heads, self.head_dim)\n",
    "        cache_k = torch.zeros(cache_shape, dtype=dtype, device=device)\n",
    "        cache_v = torch.zeros(cache_shape, dtype=dtype, device=device)\n",
    "        self.register_buffer(\"cache_k\", cache_k, persistent=False)\n",
    "        self.register_buffer(\"cache_v\", cache_v, persistent=False)\n",
    "\n",
    "    def del_kv_cache(self):\n",
    "        self.cache_k = None\n",
    "        self.cache_v = None\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        pos_embed: Tuple[torch.Tensor, torch.Tensor],\n",
    "        start_pos: Optional[Union[int, torch.Tensor]] = None,\n",
    "    ):\n",
    "        bsz, seqlen, _ = x.shape\n",
    "        xq, xk, xv = self.q_proj(x), self.k_proj(x), self.v_proj(x)\n",
    "        xq = xq.view(bsz, seqlen, self.n_heads, self.head_dim)\n",
    "        xk = xk.view(bsz, seqlen, self.n_kv_heads, self.head_dim)\n",
    "        xv = xv.view(bsz, seqlen, self.n_kv_heads, self.head_dim)\n",
    "\n",
    "        cos, sin = pos_embed\n",
    "        xq, xk = apply_rotary_pos_emb(xq, xk, cos, sin, unsqueeze_dim=2)\n",
    "        if start_pos is not None:\n",
    "            # inference mode\n",
    "            end_pos = start_pos + seqlen\n",
    "            self.cache_k[:bsz, start_pos:end_pos, :, :] = xk\n",
    "            self.cache_v[:bsz, start_pos:end_pos, :, :] = xv\n",
    "            output = torch.nn.functional.scaled_dot_product_attention(\n",
    "                query=xq.transpose(1, 2),\n",
    "                key=self.cache_k[:bsz, :end_pos].transpose(1, 2),\n",
    "                value=self.cache_v[:bsz, :end_pos].transpose(1, 2),\n",
    "                is_causal=True if seqlen > 1 else False,\n",
    "                enable_gqa=True,\n",
    "            ).transpose(1, 2)\n",
    "        else:\n",
    "            # training mode\n",
    "            output = torch.nn.functional.scaled_dot_product_attention(\n",
    "                query=xq.transpose(1, 2),\n",
    "                key=xk.transpose(1, 2),\n",
    "                value=xv.transpose(1, 2),\n",
    "                is_causal=True,\n",
    "                enable_gqa=True,\n",
    "            ).transpose(1, 2)\n",
    "        output = output.reshape(bsz, seqlen, -1)\n",
    "        return self.o_proj(output)\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: int,\n",
    "        intermediate_size: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.up_proj = nn.Linear(dim, intermediate_size, bias=False)\n",
    "        self.down_proj = nn.Linear(intermediate_size, dim, bias=False)\n",
    "        self.gate_proj = nn.Linear(dim, intermediate_size, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.down_proj(F.silu(self.gate_proj(x)) * self.up_proj(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, layer_id: int, args: Qwen2Config):\n",
    "        super().__init__()\n",
    "        self.n_heads = args.num_attention_heads\n",
    "        self.dim = args.hidden_size\n",
    "        self.head_dim = args.hidden_size // args.num_attention_heads\n",
    "        self.self_attn = Attention(args)\n",
    "        self.mlp = FeedForward(\n",
    "            dim=args.hidden_size,\n",
    "            intermediate_size=args.intermediate_size,\n",
    "        )\n",
    "        self.layer_id = layer_id\n",
    "        self.input_layernorm = RMSNorm(args.hidden_size, eps=args.rms_norm_eps)\n",
    "        self.post_attention_layernorm = RMSNorm(args.hidden_size, eps=args.rms_norm_eps)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        pos_embed: Tuple[torch.Tensor, torch.Tensor],\n",
    "        start_pos: Optional[Union[int, torch.Tensor]] = None,\n",
    "    ):\n",
    "        h = x + self.self_attn(self.input_layernorm(x), pos_embed, start_pos=start_pos)\n",
    "        out = h + self.mlp(self.post_attention_layernorm(h))\n",
    "        return out\n",
    "\n",
    "\n",
    "class Qwen2RotaryEmbedding(nn.Module):\n",
    "    def __init__(self, config: Qwen2Config, device: torch.device):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        base = config.rope_theta\n",
    "        dim = config.hidden_size // config.num_attention_heads\n",
    "        with torch.autocast(device_type=device.type, dtype=torch.float32):\n",
    "            inv_freq = 1.0 / (\n",
    "                base\n",
    "                ** (torch.arange(0, dim, 2, dtype=torch.int64).float().to(device) / dim)\n",
    "            )\n",
    "        self.register_buffer(\"inv_freq\", inv_freq, persistent=False)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward(self, x, pos):\n",
    "        inv_freq = self.inv_freq[None, :, None].float().expand(pos.shape[0], -1, 1)\n",
    "        pos = pos[:, None, :].float()\n",
    "        device_type = x.device.type\n",
    "        with torch.autocast(device_type=device_type, enabled=False):\n",
    "            freqs = (inv_freq.float().to(x.device) @ pos.float()).transpose(1, 2)\n",
    "            emb = torch.cat((freqs, freqs), dim=-1)\n",
    "            cos = emb.cos()\n",
    "            sin = emb.sin()\n",
    "        return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, params: Qwen2Config, device: torch.device):\n",
    "        super().__init__()\n",
    "        self.params = params\n",
    "        self.vocab_size = params.vocab_size\n",
    "        self.n_layers = params.num_hidden_layers\n",
    "\n",
    "        self.embed_tokens = torch.nn.Embedding(params.vocab_size, params.hidden_size)\n",
    "        with torch.device(device):\n",
    "            self.rotary_emb = Qwen2RotaryEmbedding(config=params, device=device)\n",
    "\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        for layer_id in range(params.num_hidden_layers):\n",
    "            self.layers.append(TransformerBlock(layer_id, params))\n",
    "\n",
    "        self.norm = RMSNorm(params.hidden_size, eps=params.rms_norm_eps)\n",
    "        if not params.tie_word_embeddings:\n",
    "            self.lm_head = nn.Linear(params.hidden_size, params.vocab_size, bias=False)\n",
    "\n",
    "    def output_proj(self, x):\n",
    "        if self.params.tie_word_embeddings:\n",
    "            return x @ self.embed_tokens.weight.T\n",
    "        else:\n",
    "            return self.lm_head(x)\n",
    "\n",
    "    def forward(self, tokens: torch.Tensor):\n",
    "        _bsz, seqlen = tokens.shape\n",
    "        h = self.embed_tokens(tokens)\n",
    "        pos = torch.arange(0, seqlen, device=tokens.device, dtype=torch.int32)\n",
    "        pos_emb = self.rotary_emb(h, pos[None, :])\n",
    "\n",
    "        pipe = []\n",
    "        for layer in self.layers:\n",
    "            pipe.append(lambda x, layer=layer: layer(x, pos_emb))\n",
    "        pipe.append(self.norm.forward)\n",
    "        pipe.append(self.output_proj)\n",
    "        return torch.utils.checkpoint.checkpoint_sequential(\n",
    "            pipe, len(pipe), h, use_reentrant=False\n",
    "        )\n",
    "\n",
    "    def inference(self, tokens: torch.Tensor, start_pos: Union[int, torch.Tensor]):\n",
    "        _bsz, seqlen = tokens.shape\n",
    "        del _bsz\n",
    "        h = self.embed_tokens(tokens)\n",
    "\n",
    "        pos = torch.arange(0, seqlen, device=tokens.device, dtype=torch.int32)[None, :]\n",
    "        if isinstance(start_pos, torch.Tensor):\n",
    "            pos = pos + start_pos[:, None]\n",
    "        else:  # int\n",
    "            pos.add_(start_pos)\n",
    "        pos_emb = self.rotary_emb(h, pos)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            h = layer(h, pos_emb, start_pos=start_pos)\n",
    "\n",
    "        # only need the hidden state of the last token\n",
    "        # to predict the next token\n",
    "        h = h[:, -1:, :]\n",
    "        h = self.norm(h)\n",
    "\n",
    "        output = self.output_proj(h)\n",
    "        return output\n",
    "\n",
    "    def init_kv_cache(\n",
    "        self,\n",
    "        max_batch_size: int,\n",
    "        max_seq_len: int,\n",
    "        device: torch.device,\n",
    "        dtype: torch.dtype,\n",
    "    ):\n",
    "        for layer in self.layers:\n",
    "            layer.self_attn.init_kv_cache(\n",
    "                max_batch_size, max_seq_len, dtype=dtype, device=device\n",
    "            )\n",
    "\n",
    "    def del_kv_cache(self):\n",
    "        for layer in self.layers:\n",
    "            layer.self_attn.del_kv_cache()\n",
    "\n",
    "    @classmethod\n",
    "    def from_pretrained(cls, ckpt_path, device: torch.device):\n",
    "        config_file = Path(ckpt_path) / \"config.json\"\n",
    "        with open(config_file, \"r\") as f:\n",
    "            config = json.load(f)\n",
    "        args = Qwen2Config(\n",
    "            attention_dropout=config[\"attention_dropout\"],\n",
    "            bos_token_id=config[\"bos_token_id\"],\n",
    "            eos_token_id=config[\"eos_token_id\"],\n",
    "            hidden_act=config[\"hidden_act\"],\n",
    "            hidden_size=config[\"hidden_size\"],\n",
    "            initializer_range=config[\"initializer_range\"],\n",
    "            intermediate_size=config[\"intermediate_size\"],\n",
    "            max_position_embeddings=config[\"max_position_embeddings\"],\n",
    "            max_window_layers=config[\"max_window_layers\"],\n",
    "            model_type=config[\"model_type\"],\n",
    "            num_hidden_layers=config[\"num_hidden_layers\"],\n",
    "            num_attention_heads=config[\"num_attention_heads\"],\n",
    "            num_key_value_heads=config[\"num_key_value_heads\"],\n",
    "            vocab_size=config[\"vocab_size\"],\n",
    "            rms_norm_eps=config[\"rms_norm_eps\"],\n",
    "            rope_theta=config[\"rope_theta\"],\n",
    "            sliding_window=config[\"sliding_window\"],\n",
    "            use_sliding_window=config[\"use_sliding_window\"],\n",
    "            use_cache=config[\"use_cache\"],\n",
    "            tie_word_embeddings=config[\"tie_word_embeddings\"],\n",
    "            torch_dtype=config[\"torch_dtype\"],\n",
    "        )\n",
    "        with torch.device(\"meta\"):\n",
    "            model = cls(params=args, device=device)\n",
    "\n",
    "        import safetensors.torch\n",
    "\n",
    "        model_weight_files = sorted(Path(ckpt_path).glob(\"model*.safetensors\"))\n",
    "        weights = {}\n",
    "        for file in model_weight_files:\n",
    "            weights.update(safetensors.torch.load_file(file, device=\"cpu\"))\n",
    "        # remove \"model.\" prefix from keys\n",
    "        weights = {k.replace(\"model.\", \"\"): v for k, v in weights.items()}\n",
    "        model.load_state_dict(weights, strict=True, assign=True)\n",
    "        return model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88ae8f7",
   "metadata": {},
   "source": [
    "Define data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "066721fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Episode:\n",
    "    \"\"\"Store all relevant information of an episode.\"\"\"\n",
    "\n",
    "    prefix: str\n",
    "    text: str\n",
    "    prefix_token_ids: List[int]\n",
    "    prefix_tokens: List[str]\n",
    "    generated_token_ids: List[int]\n",
    "    is_finished: bool\n",
    "    reward: float\n",
    "    reward_info: Dict[str, float]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class MiniBatch:\n",
    "    \"\"\"Batch of data for each training step.\"\"\"\n",
    "\n",
    "    prefix: List[str]\n",
    "    prefix_tokens: List[List[str]]\n",
    "    prefix_token_ids: List[List[int]]\n",
    "    numbers: List[List[int]]\n",
    "    target: List[int]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db958313",
   "metadata": {},
   "source": [
    "We are going to train the Qwen2.5 models on the [CountDown task](https://huggingface.co/datasets/Jiayi-Pan/Countdown-Tasks-3to4). Given a list of 3 or 4 numbers and a target number, the model needs to generate a mathematical expression using simple arithmetic operations (+, -, *, /) that evaluates to the target number. For example:\n",
    "\n",
    "```\n",
    "Question: Given 1 2 3 4 and a target number 11. Show an expression that evaluates to 11.\n",
    "Answer: 1 + (2 * 3) + 4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb1848bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_MESSAGE = (\n",
    "    \"You are a helpful assistant. You first think about the reasoning process \"\n",
    "    \"in your mind and then provide the user with the answer.\"\n",
    ")\n",
    "USER_TEMPLATE = (\n",
    "    \"Using the numbers {numbers}, create an equation that equals {target}. \"\n",
    "    \"You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. \"\n",
    "    \"Show your work in <think> </think> tags. \"\n",
    "    \"And return the final answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>.\"\n",
    ")\n",
    "RESPONSE_PROMPT = \"Let me solve this step by step.\\n<think>\"\n",
    "\n",
    "\n",
    "class CountdownTasksDataset(Dataset):\n",
    "    \"\"\"Prepare Countdown Tasks for training\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        tokenizer: Tokenizer,\n",
    "        data_path: str,\n",
    "        split: str = \"train\",\n",
    "        test_size: int = 100,\n",
    "    ):\n",
    "        data = pd.read_parquet(Path(data_path) / \"data\")\n",
    "        # use the last `test_size` examples for testing\n",
    "        self.data = (\n",
    "            data.iloc[:-test_size] if split == \"train\" else data.iloc[-test_size:]\n",
    "        )\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data.iloc[idx].to_dict()\n",
    "        item.update(self.encode_prefix(item[\"nums\"], item[\"target\"]))\n",
    "        return item\n",
    "\n",
    "    def encode_prefix(self, numbers: List[int], target: int):\n",
    "        \"\"\"Prefix is the *actual* input to the model.\"\"\"\n",
    "        user_message = USER_TEMPLATE.format(numbers=numbers, target=target)\n",
    "        prefix = self.tokenizer.encode_chat_with_response_prompt(\n",
    "            [\n",
    "                {\"role\": \"system\", \"content\": SYSTEM_MESSAGE},\n",
    "                {\"role\": \"user\", \"content\": user_message},\n",
    "            ],\n",
    "            RESPONSE_PROMPT,\n",
    "        )\n",
    "        tokens = self.tokenizer.tokenize(prefix)\n",
    "        return {\n",
    "            \"prefix\": prefix,\n",
    "            \"prefix_tokens\": tokens.tokens,\n",
    "            \"prefix_token_ids\": tokens.ids,\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_fn(batch: List[Dict[str, Any]]) -> MiniBatch:\n",
    "        \"\"\"Collate examples into a batch.\"\"\"\n",
    "        numbers = [item[\"nums\"] for item in batch]\n",
    "        target = [item[\"target\"] for item in batch]\n",
    "        prefix = [item[\"prefix\"] for item in batch]\n",
    "        prefix_tokens = [item[\"prefix_tokens\"] for item in batch]\n",
    "        prefix_token_ids = [item[\"prefix_token_ids\"] for item in batch]\n",
    "        return MiniBatch(\n",
    "            numbers=numbers,\n",
    "            target=target,\n",
    "            prefix=prefix,\n",
    "            prefix_tokens=prefix_tokens,\n",
    "            prefix_token_ids=prefix_token_ids,\n",
    "        )\n",
    "\n",
    "\n",
    "def format_reward_function(response: str, end_token: Optional[str] = None) -> float:\n",
    "    \"\"\"\n",
    "    Checks if the response follows the format <think>...</think><answer>...</answer>\n",
    "    \"\"\"\n",
    "    # Strip end token if present\n",
    "    if end_token and response.endswith(end_token):\n",
    "        response = response[: -len(end_token)]\n",
    "\n",
    "    think_regex = r\"<think>.*?<\\/think>\"\n",
    "    answer_regex = r\"<answer>.*?<\\/answer>\"\n",
    "    full_format_regex = r\"^<think>.*?<\\/think>\\n<answer>.*?<\\/answer>$\"\n",
    "\n",
    "    think_match = re.search(think_regex, response, re.DOTALL)\n",
    "    answer_match = re.search(answer_regex, response, re.DOTALL)\n",
    "    full_format_match = re.match(full_format_regex, response, re.DOTALL)\n",
    "\n",
    "    if full_format_match:\n",
    "        return 1.0\n",
    "\n",
    "    reward = 0.0\n",
    "\n",
    "    if think_match:\n",
    "        reward += 0.1\n",
    "\n",
    "    if answer_match:\n",
    "        reward += 0.5\n",
    "\n",
    "    return reward\n",
    "\n",
    "\n",
    "def answer_reward_function(\n",
    "    response: str, numbers: List[int] = None, target: int = None\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Checks if the answer uses all numbers exactly once and evaluates to the target\n",
    "    \"\"\"\n",
    "    answer_regex = r\"<answer>(.*?)<\\/answer>\"\n",
    "    answer_match = re.search(answer_regex, response, re.DOTALL)\n",
    "    if not answer_match:\n",
    "        return 0.0\n",
    "\n",
    "    answer_content = answer_match.group(1)\n",
    "    if not answer_content:\n",
    "        return 0.0\n",
    "\n",
    "    allowed_chars = r\"^[0-9+\\-*/() ]+$\"\n",
    "    if not re.match(allowed_chars, answer_content):\n",
    "        return 0.0\n",
    "\n",
    "    # Check if the answer uses all numbers exactly once\n",
    "    used_numbers = [int(n) for n in re.findall(r\"\\d+\", answer_content)]\n",
    "    if sorted(used_numbers) != sorted(numbers):\n",
    "        return 0.0\n",
    "\n",
    "    # Check if the answer evaluates to the target\n",
    "    try:\n",
    "        result = eval(answer_content, {\"__builtins__\": None}, {})\n",
    "        if abs(float(result) - float(target)) < 1e-5:\n",
    "            return 1.0\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def reward_function(\n",
    "    response: str,\n",
    "    numbers: List[int] = None,\n",
    "    target: int = None,\n",
    "    end_token: str = None,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Reward function for Countdown Tasks.\n",
    "\n",
    "    Total reward = 0.1 * format_reward + answer_reward\n",
    "    \"\"\"\n",
    "    format_reward = format_reward_function(\"<think>\" + response, end_token)\n",
    "    answer_reward = answer_reward_function(response, numbers, target)\n",
    "    return {\n",
    "        \"reward\": format_reward * 0.1 + answer_reward,\n",
    "        \"reward_info\": {\n",
    "            \"format_reward\": format_reward,\n",
    "            \"answer_reward\": answer_reward,\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f78cd9",
   "metadata": {},
   "source": [
    "GRPO algorithm implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5698529",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@torch.no_grad()\n",
    "def rollout(\n",
    "    model: Transformer,\n",
    "    batch: MiniBatch,\n",
    "    tokenizer: Tokenizer,\n",
    "    max_gen_len: int,\n",
    "    num_answer_per_question: int,\n",
    "    reward_function: Callable,\n",
    "    device: torch.device,\n",
    "    dtype: torch.dtype,\n",
    ") -> List[Episode]:\n",
    "    end_token = tokenizer.eos_token\n",
    "    end_token_id = tokenizer.eos_token_id\n",
    "    pad_token_id = tokenizer.pad_token_id\n",
    "    prefix_token_ids = batch.prefix_token_ids\n",
    "    bsz = len(batch.prefix) * num_answer_per_question\n",
    "    min_prompt_len = min(len(t) for t in prefix_token_ids)\n",
    "    max_prompt_len = max(len(t) for t in prefix_token_ids)\n",
    "    total_len = max_gen_len + max_prompt_len\n",
    "    model.init_kv_cache(\n",
    "        max_batch_size=bsz,\n",
    "        max_seq_len=total_len,\n",
    "        device=device,\n",
    "        dtype=dtype,\n",
    "    )\n",
    "    tokens = torch.full((bsz, total_len), pad_token_id, dtype=torch.long, device=device)\n",
    "    for k, t in enumerate(prefix_token_ids):\n",
    "        offset = k * num_answer_per_question\n",
    "        for i in range(num_answer_per_question):\n",
    "            tokens[offset + i, : len(t)] = torch.tensor(\n",
    "                t, dtype=torch.long, device=device\n",
    "            )\n",
    "\n",
    "    prev_pos = 0\n",
    "    input_text_mask = tokens != pad_token_id\n",
    "    assert min_prompt_len < total_len\n",
    "    is_finished = torch.zeros((bsz,), dtype=torch.bool, device=device)\n",
    "\n",
    "    for cur_pos in range(min_prompt_len, total_len):\n",
    "        print(\n",
    "            f\"\\r* Generating trajectories: {cur_pos-min_prompt_len:>4d}/{total_len-min_prompt_len:>4d}\",\n",
    "            flush=True,\n",
    "            end=\"\",\n",
    "        )\n",
    "        with torch.autocast(device_type=device.type, dtype=dtype):\n",
    "            logits = model.inference(tokens[:, prev_pos:cur_pos], prev_pos)\n",
    "        probs = torch.softmax(logits[:, -1], dim=-1)\n",
    "        next_token = torch.multinomial(probs, num_samples=1)\n",
    "        next_token = next_token.reshape(-1)\n",
    "        next_token = torch.where(\n",
    "            input_text_mask[:, cur_pos], tokens[:, cur_pos], next_token\n",
    "        )\n",
    "        # if an rollout is finished, we fill the rest of the tokens with pad_token_id\n",
    "        next_token = torch.where(is_finished, pad_token_id, next_token)\n",
    "        tokens[:, cur_pos] = next_token\n",
    "        if end_token_id is not None:\n",
    "            is_end_token = next_token == end_token_id\n",
    "            is_generated_token = ~input_text_mask[:, cur_pos]\n",
    "            is_finished = is_finished | (is_end_token & is_generated_token)\n",
    "        prev_pos = cur_pos\n",
    "        if is_finished.all():\n",
    "            break\n",
    "    model.del_kv_cache()\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    is_finished_list = is_finished.tolist()\n",
    "    tokens_list = tokens.tolist()\n",
    "\n",
    "    # prepare the output episodes\n",
    "    episodes = []\n",
    "    for i in range(bsz // num_answer_per_question):\n",
    "        for j in range(num_answer_per_question):\n",
    "            idx = i * num_answer_per_question + j\n",
    "            generated_token_ids = tokens_list[idx][len(batch.prefix_token_ids[i]) :]\n",
    "            # remove padding tokens\n",
    "            if pad_token_id in generated_token_ids:\n",
    "                generated_token_ids = generated_token_ids[\n",
    "                    : generated_token_ids.index(pad_token_id)\n",
    "                ]\n",
    "            generated_text = tokenizer.detokenize(generated_token_ids)\n",
    "            rewards = reward_function(\n",
    "                response=generated_text,\n",
    "                numbers=batch.numbers[i],\n",
    "                target=batch.target[i],\n",
    "                end_token=end_token,\n",
    "            )\n",
    "            episode = Episode(\n",
    "                prefix=batch.prefix[i],\n",
    "                text=batch.prefix[i] + generated_text,\n",
    "                prefix_token_ids=batch.prefix_token_ids[i],\n",
    "                prefix_tokens=batch.prefix_tokens[i],\n",
    "                generated_token_ids=generated_token_ids,\n",
    "                is_finished=is_finished_list[idx],\n",
    "                reward=rewards[\"reward\"],\n",
    "                reward_info=rewards[\"reward_info\"],\n",
    "            )\n",
    "            episodes.append(episode)\n",
    "    # clear the output line\n",
    "    print(\"\\r\", end=\" \" * 100, flush=True)\n",
    "    return episodes\n",
    "\n",
    "\n",
    "def normalize_rewards_per_group(episodes: List[Episode]) -> List[Episode]:\n",
    "    \"\"\"Normalize rewards per group. A group is defined by the prefix.\"\"\"\n",
    "    groups = defaultdict(list)\n",
    "    for episode in episodes:\n",
    "        groups[tuple(episode.prefix)].append(episode)\n",
    "    output = []\n",
    "    for group in groups.values():\n",
    "        group_rewards = [item.reward for item in group]\n",
    "        mean_reward = np.mean(group_rewards)\n",
    "        std_reward = np.std(group_rewards)\n",
    "        for episode in group:\n",
    "            normalized_reward = (episode.reward - mean_reward) / (std_reward + 1e-4)\n",
    "            episode = dataclasses.replace(episode, reward=normalized_reward)\n",
    "            output.append(episode)\n",
    "    return output\n",
    "\n",
    "\n",
    "def compute_entropy(logits: torch.Tensor) -> torch.Tensor:\n",
    "    probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "    entropy = torch.logsumexp(logits, dim=-1) - torch.sum(probs * logits, dim=-1)\n",
    "    return entropy\n",
    "\n",
    "\n",
    "def update_policy(\n",
    "    model,\n",
    "    optimizer,\n",
    "    episodes: List[Episode],\n",
    "    micro_batch_size: int,\n",
    "    pad_token_id: int,\n",
    "    max_grad_norm: float,\n",
    "    device: torch.device,\n",
    "    dtype: torch.dtype,\n",
    "):\n",
    "    \"\"\"Update the policy using the GRPO algorithm.\"\"\"\n",
    "    episodes = normalize_rewards_per_group(episodes)\n",
    "    # sort episodes by token length for efficient (micro-)batching\n",
    "    episodes.sort(key=lambda x: len(x.prefix_token_ids) + len(x.generated_token_ids))\n",
    "    num_micro_batches = math.ceil(len(episodes) / micro_batch_size)\n",
    "    num_target_tokens = sum(len(episode.generated_token_ids) for episode in episodes)\n",
    "    entropy = 0.0\n",
    "\n",
    "    for i in range(0, len(episodes), micro_batch_size):\n",
    "        print(\n",
    "            f\"\\r* Computing policy gradient: {i:>2d}/{len(episodes):>2d}\",\n",
    "            flush=True,\n",
    "            end=\"\",\n",
    "        )\n",
    "        j = min(i + micro_batch_size, len(episodes))\n",
    "        batch_episodes = episodes[i:j]\n",
    "        batch_lengths = [\n",
    "            len(episode.prefix_token_ids) + len(episode.generated_token_ids)\n",
    "            for episode in batch_episodes\n",
    "        ]\n",
    "        batch_max_length = max(batch_lengths)\n",
    "        batch_token_ids = [\n",
    "            episode.prefix_token_ids\n",
    "            + episode.generated_token_ids\n",
    "            + [pad_token_id] * (batch_max_length - batch_lengths[i])\n",
    "            for i, episode in enumerate(batch_episodes)\n",
    "        ]\n",
    "        batch_masks = [\n",
    "            [0] * len(episode.prefix_token_ids)\n",
    "            + [1] * len(episode.generated_token_ids)\n",
    "            + [0] * (batch_max_length - batch_lengths[i])\n",
    "            for i, episode in enumerate(batch_episodes)\n",
    "        ]\n",
    "        batch_advantages = [episode.reward for episode in batch_episodes]\n",
    "        batch_token_ids = torch.tensor(batch_token_ids, device=device, dtype=torch.long)\n",
    "        batch_masks = torch.tensor(batch_masks, device=device, dtype=torch.bool)\n",
    "        batch_advantages = torch.tensor(\n",
    "            batch_advantages, device=device, dtype=torch.float32\n",
    "        )\n",
    "\n",
    "        with torch.autocast(device_type=device.type, dtype=dtype):\n",
    "            input_token_ids = batch_token_ids[:, :-1]\n",
    "            target_token_ids = batch_token_ids[:, 1:]\n",
    "            target_masks = batch_masks[:, 1:]\n",
    "            logits = model.forward(input_token_ids).float()\n",
    "\n",
    "        log_probs = -torch.nn.functional.cross_entropy(\n",
    "            logits.reshape(-1, logits.size(-1)),\n",
    "            target_token_ids.reshape(-1),\n",
    "            ignore_index=pad_token_id,\n",
    "            reduction=\"none\",\n",
    "        ).reshape(input_token_ids.shape[0], -1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            token_entropy = compute_entropy(logits)\n",
    "            entropy = entropy + (token_entropy * target_masks).sum() / num_target_tokens\n",
    "\n",
    "        obj = log_probs * batch_advantages[:, None]\n",
    "        # per-token objective\n",
    "        obj = (obj * target_masks).sum() / num_target_tokens\n",
    "        loss = -obj\n",
    "        loss.backward()\n",
    "\n",
    "    # update the policy\n",
    "    grad_norm = torch.nn.utils.clip_grad_norm_(\n",
    "        model.parameters(), max_norm=max_grad_norm\n",
    "    )\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    return {\n",
    "        \"loss\": loss.item(),\n",
    "        \"grad_norm\": grad_norm.item(),\n",
    "        \"entropy\": entropy.item(),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bf970f",
   "metadata": {},
   "source": [
    "Training functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d009baa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, tokenizer, device, dtype, config):\n",
    "    test_dataset = CountdownTasksDataset(\n",
    "        data_path=config[\"data\"][\"path\"],\n",
    "        tokenizer=tokenizer,\n",
    "        split=\"test\",\n",
    "        test_size=config[\"data\"][\"test_size\"],\n",
    "    )\n",
    "    generator = torch.Generator(device=device)\n",
    "    # We reduce the batch size by half as we want to\n",
    "    # generate twice as long trajectories.\n",
    "    dataloader = DataLoader(\n",
    "        test_dataset,\n",
    "        shuffle=False,\n",
    "        collate_fn=CountdownTasksDataset.collate_fn,\n",
    "        generator=generator,\n",
    "        batch_size=config[\"training\"][\"batch_size\"] // 2,\n",
    "        drop_last=False,\n",
    "    )\n",
    "    success = []\n",
    "    for batch in dataloader:\n",
    "        episodes = rollout(\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            batch=batch,\n",
    "            max_gen_len=config[\"training\"][\"max_gen_len\"] * 2,\n",
    "            num_answer_per_question=1,\n",
    "            reward_function=reward_function,\n",
    "            device=device,\n",
    "            dtype=dtype,\n",
    "        )\n",
    "        success.extend([episode.reward_info[\"answer_reward\"] for episode in episodes])\n",
    "    return np.mean(success)\n",
    "\n",
    "\n",
    "def main(config_path: str):\n",
    "    with open(config_path, \"r\") as f:\n",
    "        config = yaml.safe_load(f)\n",
    "\n",
    "    pretrained_model_path = Path(config[\"model\"][\"pretrained_model_path\"])\n",
    "    device = torch.device(config[\"model\"][\"device\"])\n",
    "    dtype_map = {\n",
    "        \"bfloat16\": torch.bfloat16,\n",
    "        \"float16\": torch.float16,\n",
    "        \"float32\": torch.float32,\n",
    "    }\n",
    "    dtype = dtype_map.get(config[\"model\"][\"dtype\"], torch.bfloat16)\n",
    "    torch.set_default_device(device)\n",
    "    torch.random.manual_seed(config[\"training\"][\"random_seed\"])\n",
    "    BATCH_SIZE = config[\"training\"][\"batch_size\"]\n",
    "    NUM_QUESTIONS_PER_BATCH = config[\"training\"][\"num_questions_per_batch\"]\n",
    "    NUM_ANSWERS_PER_QUESTION = BATCH_SIZE // NUM_QUESTIONS_PER_BATCH\n",
    "\n",
    "    current_time = datetime.now().strftime(r\"%Y%m%d-%H%M%S\")\n",
    "    tb_writer = SummaryWriter(log_dir=f\"{config['training']['log_dir']}/{current_time}\")\n",
    "    tokenizer = Tokenizer(str(pretrained_model_path / \"tokenizer.json\"))\n",
    "\n",
    "    train_dataset = CountdownTasksDataset(\n",
    "        data_path=config[\"data\"][\"path\"],\n",
    "        tokenizer=tokenizer,\n",
    "        split=\"train\",\n",
    "        test_size=config[\"data\"][\"test_size\"],\n",
    "    )\n",
    "    generator = torch.Generator(device=device)\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        shuffle=True,\n",
    "        collate_fn=CountdownTasksDataset.collate_fn,\n",
    "        generator=generator,\n",
    "        batch_size=NUM_QUESTIONS_PER_BATCH,\n",
    "    )\n",
    "\n",
    "    model = Transformer.from_pretrained(pretrained_model_path, device=device).train()\n",
    "\n",
    "    optimizer = MemoryEfficientAdamW(\n",
    "        model.parameters(),\n",
    "        lr=config[\"training\"][\"learning_rate\"],\n",
    "        weight_decay=config[\"training\"][\"weight_decay\"],\n",
    "        betas=config[\"training\"][\"betas\"],\n",
    "        enabled=config[\"training\"][\"memory_efficient_adamw\"],\n",
    "    )\n",
    "\n",
    "    start_time = time.time()\n",
    "    ckpt_dir = Path(config[\"training\"][\"ckpt_dir\"])\n",
    "    ckpt_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader, start=1):\n",
    "        episodes = rollout(\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            batch=batch,\n",
    "            max_gen_len=config[\"training\"][\"max_gen_len\"],\n",
    "            num_answer_per_question=NUM_ANSWERS_PER_QUESTION,\n",
    "            reward_function=reward_function,\n",
    "            device=device,\n",
    "            dtype=dtype,\n",
    "        )\n",
    "        if config[\"training\"][\"skip_unfinished_episodes\"]:\n",
    "            episodes = [episode for episode in episodes if episode.is_finished]\n",
    "        results = update_policy(\n",
    "            model=model,\n",
    "            optimizer=optimizer,\n",
    "            episodes=episodes,\n",
    "            micro_batch_size=config[\"training\"][\"micro_batch_size\"],\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            max_grad_norm=config[\"training\"][\"max_grad_norm\"],\n",
    "            device=device,\n",
    "            dtype=dtype,\n",
    "        )\n",
    "        torch.cuda.synchronize()\n",
    "        end_time = time.time()\n",
    "        duration = end_time - start_time\n",
    "        start_time = end_time\n",
    "\n",
    "        # compute and log important metrics\n",
    "        reward = [episode.reward for episode in episodes]\n",
    "        formatted_reward = [\n",
    "            episode.reward_info[\"format_reward\"] for episode in episodes\n",
    "        ]\n",
    "        answer_reward = [episode.reward_info[\"answer_reward\"] for episode in episodes]\n",
    "        num_finished_episodes = sum(episode.is_finished for episode in episodes)\n",
    "        mean_reward = np.mean(reward)\n",
    "        std_reward = np.std(reward)\n",
    "        success_rate = np.mean(answer_reward)\n",
    "        format_reward = np.mean(formatted_reward)\n",
    "        grad_norm = results[\"grad_norm\"]\n",
    "        entropy = results[\"entropy\"]\n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        loss = results[\"loss\"]\n",
    "        mean_response_len = np.mean(\n",
    "            [len(episode.generated_token_ids) for episode in episodes]\n",
    "        )\n",
    "        print(\n",
    "            f\"\\rStep {step}, mean_reward: {mean_reward:.2f}, \"\n",
    "            f\"train success_rate: {success_rate:.2f}, \"\n",
    "            f\"grad_norm: {grad_norm:.2f}, duration: {duration:.2f}, \"\n",
    "            f\"num_finished_episodes: {num_finished_episodes}, \"\n",
    "            f\"mean_response_len: {mean_response_len:.2f}, \"\n",
    "            f\"entropy: {entropy:.2f}\"\n",
    "        )\n",
    "        if step % config[\"training\"][\"eval_interval\"] == 0:\n",
    "            eval_success_rate = evaluate(model, tokenizer, device, dtype, config)\n",
    "            print(f\"\\rEval success rate: {eval_success_rate:.2f}\" + \" \" * 100)\n",
    "            tb_writer.add_scalar(\"success_rate/eval\", eval_success_rate, step)\n",
    "\n",
    "        tb_writer.add_scalar(\"loss\", loss, step)\n",
    "        tb_writer.add_scalar(\"mean_reward\", mean_reward, step)\n",
    "        tb_writer.add_scalar(\"std_reward\", std_reward, step)\n",
    "        tb_writer.add_scalar(\"success_rate/train\", success_rate, step)\n",
    "        tb_writer.add_scalar(\"format_reward\", format_reward, step)\n",
    "        tb_writer.add_scalar(\"grad_norm\", grad_norm, step)\n",
    "        tb_writer.add_scalar(\"duration\", duration, step)\n",
    "        tb_writer.add_scalar(\"num_finished_episodes\", num_finished_episodes, step)\n",
    "        tb_writer.add_scalar(\"learning_rate\", lr, step)\n",
    "        tb_writer.add_scalar(\"mean_response_len\", mean_response_len, step)\n",
    "        tb_writer.add_scalar(\"entropy\", entropy, step)\n",
    "        for i, episode in enumerate(episodes):\n",
    "            # TensorBoard treats text as markdown.\n",
    "            text = html.escape(episode.text)\n",
    "            tb_writer.add_text(f\"text_{i}\", f\"<pre>{text}</pre>\", step)\n",
    "\n",
    "        # save checkpoint\n",
    "        if step % config[\"training\"][\"ckpt_save_interval\"] == 0:\n",
    "            output_file = ckpt_dir / f\"ckpt_{step:06d}.pt\"\n",
    "            torch.save(model.state_dict(), output_file)\n",
    "            print(f\"Saved checkpoint to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b2b7ba",
   "metadata": {},
   "source": [
    "Quick environment and configuration check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037d1bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function: Quick environment and configuration check\n",
    "def check_environment():\n",
    "    \"\"\"Check if the runtime environment is ready\"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Environment Check\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Check CUDA\n",
    "    print(f\"PyTorch Version: {torch.__version__}\")\n",
    "    print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "        print(f\"GPU Count: {torch.cuda.device_count()}\")\n",
    "        print(f\"Current GPU: {torch.cuda.current_device()}\")\n",
    "        print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    \n",
    "    # Check configuration files\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"Configuration File Check\")\n",
    "    print(\"=\" * 50)\n",
    "    config_files = [\"config.yaml\", \"config_24GB.yaml\"]\n",
    "    for config_file in config_files:\n",
    "        if Path(config_file).exists():\n",
    "            print(f\"✓ {config_file} exists\")\n",
    "            try:\n",
    "                with open(config_file, \"r\") as f:\n",
    "                    config = yaml.safe_load(f)\n",
    "                print(f\"  - Model path: {config.get('model', {}).get('pretrained_model_path', 'N/A')}\")\n",
    "                print(f\"  - Data path: {config.get('data', {}).get('path', 'N/A')}\")\n",
    "                print(f\"  - Device: {config.get('model', {}).get('device', 'N/A')}\")\n",
    "            except Exception as e:\n",
    "                print(f\"  ✗ Error reading config file: {e}\")\n",
    "        else:\n",
    "            print(f\"✗ {config_file} does not exist\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"Check Complete\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "# Uncomment the line below to check the environment\n",
    "check_environment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9cc90d",
   "metadata": {},
   "source": [
    "Start training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c958b3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1\n",
      "Batch: MiniBatch(prefix=['<|im_start|>system\\nYou are a helpful assistant. You first think about the reasoning process in your mind and then provide the user with the answer.<|im_end|>\\n<|im_start|>user\\nUsing the numbers [18 69 74 34], create an equation that equals 91. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>.<|im_end|>\\n<|im_start|>assistant\\nLet me solve this step by step.\\n<think>', '<|im_start|>system\\nYou are a helpful assistant. You first think about the reasoning process in your mind and then provide the user with the answer.<|im_end|>\\n<|im_start|>user\\nUsing the numbers [ 4 47 11], create an equation that equals 91. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>.<|im_end|>\\n<|im_start|>assistant\\nLet me solve this step by step.\\n<think>', '<|im_start|>system\\nYou are a helpful assistant. You first think about the reasoning process in your mind and then provide the user with the answer.<|im_end|>\\n<|im_start|>user\\nUsing the numbers [83 55 33 85], create an equation that equals 86. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>.<|im_end|>\\n<|im_start|>assistant\\nLet me solve this step by step.\\n<think>', '<|im_start|>system\\nYou are a helpful assistant. You first think about the reasoning process in your mind and then provide the user with the answer.<|im_end|>\\n<|im_start|>user\\nUsing the numbers [80 52 93  7], create an equation that equals 65. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>.<|im_end|>\\n<|im_start|>assistant\\nLet me solve this step by step.\\n<think>', '<|im_start|>system\\nYou are a helpful assistant. You first think about the reasoning process in your mind and then provide the user with the answer.<|im_end|>\\n<|im_start|>user\\nUsing the numbers [72 67 41], create an equation that equals 98. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>.<|im_end|>\\n<|im_start|>assistant\\nLet me solve this step by step.\\n<think>', '<|im_start|>system\\nYou are a helpful assistant. You first think about the reasoning process in your mind and then provide the user with the answer.<|im_end|>\\n<|im_start|>user\\nUsing the numbers [10  5 98], create an equation that equals 49. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>.<|im_end|>\\n<|im_start|>assistant\\nLet me solve this step by step.\\n<think>', '<|im_start|>system\\nYou are a helpful assistant. You first think about the reasoning process in your mind and then provide the user with the answer.<|im_end|>\\n<|im_start|>user\\nUsing the numbers [55 98  7], create an equation that equals 50. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>.<|im_end|>\\n<|im_start|>assistant\\nLet me solve this step by step.\\n<think>', '<|im_start|>system\\nYou are a helpful assistant. You first think about the reasoning process in your mind and then provide the user with the answer.<|im_end|>\\n<|im_start|>user\\nUsing the numbers [19 50 60], create an equation that equals 29. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>.<|im_end|>\\n<|im_start|>assistant\\nLet me solve this step by step.\\n<think>', '<|im_start|>system\\nYou are a helpful assistant. You first think about the reasoning process in your mind and then provide the user with the answer.<|im_end|>\\n<|im_start|>user\\nUsing the numbers [12 84 42 20], create an equation that equals 50. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>.<|im_end|>\\n<|im_start|>assistant\\nLet me solve this step by step.\\n<think>', '<|im_start|>system\\nYou are a helpful assistant. You first think about the reasoning process in your mind and then provide the user with the answer.<|im_end|>\\n<|im_start|>user\\nUsing the numbers [44 30 39  3], create an equation that equals 67. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>.<|im_end|>\\n<|im_start|>assistant\\nLet me solve this step by step.\\n<think>', '<|im_start|>system\\nYou are a helpful assistant. You first think about the reasoning process in your mind and then provide the user with the answer.<|im_end|>\\n<|im_start|>user\\nUsing the numbers [46 55 35], create an equation that equals 26. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>.<|im_end|>\\n<|im_start|>assistant\\nLet me solve this step by step.\\n<think>', '<|im_start|>system\\nYou are a helpful assistant. You first think about the reasoning process in your mind and then provide the user with the answer.<|im_end|>\\n<|im_start|>user\\nUsing the numbers [69 20 68 36], create an equation that equals 92. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>.<|im_end|>\\n<|im_start|>assistant\\nLet me solve this step by step.\\n<think>', '<|im_start|>system\\nYou are a helpful assistant. You first think about the reasoning process in your mind and then provide the user with the answer.<|im_end|>\\n<|im_start|>user\\nUsing the numbers [62 89  3 61], create an equation that equals 37. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>.<|im_end|>\\n<|im_start|>assistant\\nLet me solve this step by step.\\n<think>', '<|im_start|>system\\nYou are a helpful assistant. You first think about the reasoning process in your mind and then provide the user with the answer.<|im_end|>\\n<|im_start|>user\\nUsing the numbers [21 10  6 36], create an equation that equals 20. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>.<|im_end|>\\n<|im_start|>assistant\\nLet me solve this step by step.\\n<think>', '<|im_start|>system\\nYou are a helpful assistant. You first think about the reasoning process in your mind and then provide the user with the answer.<|im_end|>\\n<|im_start|>user\\nUsing the numbers [99 75 66  5], create an equation that equals 16. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>.<|im_end|>\\n<|im_start|>assistant\\nLet me solve this step by step.\\n<think>', '<|im_start|>system\\nYou are a helpful assistant. You first think about the reasoning process in your mind and then provide the user with the answer.<|im_end|>\\n<|im_start|>user\\nUsing the numbers [11 84 65], create an equation that equals 30. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>.<|im_end|>\\n<|im_start|>assistant\\nLet me solve this step by step.\\n<think>', '<|im_start|>system\\nYou are a helpful assistant. You first think about the reasoning process in your mind and then provide the user with the answer.<|im_end|>\\n<|im_start|>user\\nUsing the numbers [28 59 35], create an equation that equals 52. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>.<|im_end|>\\n<|im_start|>assistant\\nLet me solve this step by step.\\n<think>', '<|im_start|>system\\nYou are a helpful assistant. You first think about the reasoning process in your mind and then provide the user with the answer.<|im_end|>\\n<|im_start|>user\\nUsing the numbers [60 47  4 12], create an equation that equals 59. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>.<|im_end|>\\n<|im_start|>assistant\\nLet me solve this step by step.\\n<think>', '<|im_start|>system\\nYou are a helpful assistant. You first think about the reasoning process in your mind and then provide the user with the answer.<|im_end|>\\n<|im_start|>user\\nUsing the numbers [21 90 75 32], create an equation that equals 93. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>.<|im_end|>\\n<|im_start|>assistant\\nLet me solve this step by step.\\n<think>', '<|im_start|>system\\nYou are a helpful assistant. You first think about the reasoning process in your mind and then provide the user with the answer.<|im_end|>\\n<|im_start|>user\\nUsing the numbers [48 60 64 96], create an equation that equals 78. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>.<|im_end|>\\n<|im_start|>assistant\\nLet me solve this step by step.\\n<think>', '<|im_start|>system\\nYou are a helpful assistant. You first think about the reasoning process in your mind and then provide the user with the answer.<|im_end|>\\n<|im_start|>user\\nUsing the numbers [ 2 20 33], create an equation that equals 51. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>.<|im_end|>\\n<|im_start|>assistant\\nLet me solve this step by step.\\n<think>', '<|im_start|>system\\nYou are a helpful assistant. You first think about the reasoning process in your mind and then provide the user with the answer.<|im_end|>\\n<|im_start|>user\\nUsing the numbers [68 33 65 15], create an equation that equals 75. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>.<|im_end|>\\n<|im_start|>assistant\\nLet me solve this step by step.\\n<think>', '<|im_start|>system\\nYou are a helpful assistant. You first think about the reasoning process in your mind and then provide the user with the answer.<|im_end|>\\n<|im_start|>user\\nUsing the numbers [57 67  7 10], create an equation that equals 63. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>.<|im_end|>\\n<|im_start|>assistant\\nLet me solve this step by step.\\n<think>', '<|im_start|>system\\nYou are a helpful assistant. You first think about the reasoning process in your mind and then provide the user with the answer.<|im_end|>\\n<|im_start|>user\\nUsing the numbers [52 17 19 21], create an equation that equals 86. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>.<|im_end|>\\n<|im_start|>assistant\\nLet me solve this step by step.\\n<think>', '<|im_start|>system\\nYou are a helpful assistant. You first think about the reasoning process in your mind and then provide the user with the answer.<|im_end|>\\n<|im_start|>user\\nUsing the numbers [59 30 35  6], create an equation that equals 48. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>.<|im_end|>\\n<|im_start|>assistant\\nLet me solve this step by step.\\n<think>', '<|im_start|>system\\nYou are a helpful assistant. You first think about the reasoning process in your mind and then provide the user with the answer.<|im_end|>\\n<|im_start|>user\\nUsing the numbers [74 73 90 88], create an equation that equals 80. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>.<|im_end|>\\n<|im_start|>assistant\\nLet me solve this step by step.\\n<think>', '<|im_start|>system\\nYou are a helpful assistant. You first think about the reasoning process in your mind and then provide the user with the answer.<|im_end|>\\n<|im_start|>user\\nUsing the numbers [74 84 37], create an equation that equals 86. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>.<|im_end|>\\n<|im_start|>assistant\\nLet me solve this step by step.\\n<think>', '<|im_start|>system\\nYou are a helpful assistant. You first think about the reasoning process in your mind and then provide the user with the answer.<|im_end|>\\n<|im_start|>user\\nUsing the numbers [ 9 75 18  8], create an equation that equals 78. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>.<|im_end|>\\n<|im_start|>assistant\\nLet me solve this step by step.\\n<think>', '<|im_start|>system\\nYou are a helpful assistant. You first think about the reasoning process in your mind and then provide the user with the answer.<|im_end|>\\n<|im_start|>user\\nUsing the numbers [ 9 82 89 73], create an equation that equals 54. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>.<|im_end|>\\n<|im_start|>assistant\\nLet me solve this step by step.\\n<think>', '<|im_start|>system\\nYou are a helpful assistant. You first think about the reasoning process in your mind and then provide the user with the answer.<|im_end|>\\n<|im_start|>user\\nUsing the numbers [76 32 26 32], create an equation that equals 49. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>.<|im_end|>\\n<|im_start|>assistant\\nLet me solve this step by step.\\n<think>', '<|im_start|>system\\nYou are a helpful assistant. You first think about the reasoning process in your mind and then provide the user with the answer.<|im_end|>\\n<|im_start|>user\\nUsing the numbers [76 10 82  4], create an equation that equals 100. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>.<|im_end|>\\n<|im_start|>assistant\\nLet me solve this step by step.\\n<think>', '<|im_start|>system\\nYou are a helpful assistant. You first think about the reasoning process in your mind and then provide the user with the answer.<|im_end|>\\n<|im_start|>user\\nUsing the numbers [90 85 57 49], create an equation that equals 13. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>.<|im_end|>\\n<|im_start|>assistant\\nLet me solve this step by step.\\n<think>'], prefix_tokens=[['<|im_start|>', 'system', 'Ċ', 'You', 'Ġare', 'Ġa', 'Ġhelpful', 'Ġassistant', '.', 'ĠYou', 'Ġfirst', 'Ġthink', 'Ġabout', 'Ġthe', 'Ġreasoning', 'Ġprocess', 'Ġin', 'Ġyour', 'Ġmind', 'Ġand', 'Ġthen', 'Ġprovide', 'Ġthe', 'Ġuser', 'Ġwith', 'Ġthe', 'Ġanswer', '.', '<|im_end|>', 'Ċ', '<|im_start|>', 'user', 'Ċ', 'Using', 'Ġthe', 'Ġnumbers', 'Ġ[', '1', '8', 'Ġ', '6', '9', 'Ġ', '7', '4', 'Ġ', '3', '4', '],', 'Ġcreate', 'Ġan', 'Ġequation', 'Ġthat', 'Ġequals', 'Ġ', '9', '1', '.', 'ĠYou', 'Ġcan', 'Ġuse', 'Ġbasic', 'Ġarithmetic', 'Ġoperations', 'Ġ(+', ',', 'Ġ-,', 'Ġ*,', 'Ġ/', ')', 'Ġand', 'Ġeach', 'Ġnumber', 'Ġcan', 'Ġonly', 'Ġbe', 'Ġused', 'Ġonce', '.', 'ĠShow', 'Ġyour', 'Ġwork', 'Ġin', 'Ġ<', 'think', '>', 'Ġ</', 'think', '>', 'Ġtags', '.', 'ĠAnd', 'Ġreturn', 'Ġthe', 'Ġfinal', 'Ġanswer', 'Ġin', 'Ġ<', 'answer', '>', 'Ġ</', 'answer', '>', 'Ġtags', ',', 'Ġfor', 'Ġexample', 'Ġ<', 'answer', '>', 'Ġ(', '1', 'Ġ+', 'Ġ', '2', ')', 'Ġ/', 'Ġ', '3', 'Ġ</', 'answer', '>.', '<|im_end|>', 'Ċ', '<|im_start|>', 'assistant', 'Ċ', 'Let', 'Ġme', 'Ġsolve', 'Ġthis', 'Ġstep', 'Ġby', 'Ġstep', '.Ċ', '<th', 'ink', '>'], ['<|im_start|>', 'system', 'Ċ', 'You', 'Ġare', 'Ġa', 'Ġhelpful', 'Ġassistant', '.', 'ĠYou', 'Ġfirst', 'Ġthink', 'Ġabout', 'Ġthe', 'Ġreasoning', 'Ġprocess', 'Ġin', 'Ġyour', 'Ġmind', 'Ġand', 'Ġthen', 'Ġprovide', 'Ġthe', 'Ġuser', 'Ġwith', 'Ġthe', 'Ġanswer', '.', '<|im_end|>', 'Ċ', '<|im_start|>', 'user', 'Ċ', 'Using', 'Ġthe', 'Ġnumbers', 'Ġ[', 'Ġ', '4', 'Ġ', '4', '7', 'Ġ', '1', '1', '],', 'Ġcreate', 'Ġan', 'Ġequation', 'Ġthat', 'Ġequals', 'Ġ', '9', '1', '.', 'ĠYou', 'Ġcan', 'Ġuse', 'Ġbasic', 'Ġarithmetic', 'Ġoperations', 'Ġ(+', ',', 'Ġ-,', 'Ġ*,', 'Ġ/', ')', 'Ġand', 'Ġeach', 'Ġnumber', 'Ġcan', 'Ġonly', 'Ġbe', 'Ġused', 'Ġonce', '.', 'ĠShow', 'Ġyour', 'Ġwork', 'Ġin', 'Ġ<', 'think', '>', 'Ġ</', 'think', '>', 'Ġtags', '.', 'ĠAnd', 'Ġreturn', 'Ġthe', 'Ġfinal', 'Ġanswer', 'Ġin', 'Ġ<', 'answer', '>', 'Ġ</', 'answer', '>', 'Ġtags', ',', 'Ġfor', 'Ġexample', 'Ġ<', 'answer', '>', 'Ġ(', '1', 'Ġ+', 'Ġ', '2', ')', 'Ġ/', 'Ġ', '3', 'Ġ</', 'answer', '>.', '<|im_end|>', 'Ċ', '<|im_start|>', 'assistant', 'Ċ', 'Let', 'Ġme', 'Ġsolve', 'Ġthis', 'Ġstep', 'Ġby', 'Ġstep', '.Ċ', '<th', 'ink', '>'], ['<|im_start|>', 'system', 'Ċ', 'You', 'Ġare', 'Ġa', 'Ġhelpful', 'Ġassistant', '.', 'ĠYou', 'Ġfirst', 'Ġthink', 'Ġabout', 'Ġthe', 'Ġreasoning', 'Ġprocess', 'Ġin', 'Ġyour', 'Ġmind', 'Ġand', 'Ġthen', 'Ġprovide', 'Ġthe', 'Ġuser', 'Ġwith', 'Ġthe', 'Ġanswer', '.', '<|im_end|>', 'Ċ', '<|im_start|>', 'user', 'Ċ', 'Using', 'Ġthe', 'Ġnumbers', 'Ġ[', '8', '3', 'Ġ', '5', '5', 'Ġ', '3', '3', 'Ġ', '8', '5', '],', 'Ġcreate', 'Ġan', 'Ġequation', 'Ġthat', 'Ġequals', 'Ġ', '8', '6', '.', 'ĠYou', 'Ġcan', 'Ġuse', 'Ġbasic', 'Ġarithmetic', 'Ġoperations', 'Ġ(+', ',', 'Ġ-,', 'Ġ*,', 'Ġ/', ')', 'Ġand', 'Ġeach', 'Ġnumber', 'Ġcan', 'Ġonly', 'Ġbe', 'Ġused', 'Ġonce', '.', 'ĠShow', 'Ġyour', 'Ġwork', 'Ġin', 'Ġ<', 'think', '>', 'Ġ</', 'think', '>', 'Ġtags', '.', 'ĠAnd', 'Ġreturn', 'Ġthe', 'Ġfinal', 'Ġanswer', 'Ġin', 'Ġ<', 'answer', '>', 'Ġ</', 'answer', '>', 'Ġtags', ',', 'Ġfor', 'Ġexample', 'Ġ<', 'answer', '>', 'Ġ(', '1', 'Ġ+', 'Ġ', '2', ')', 'Ġ/', 'Ġ', '3', 'Ġ</', 'answer', '>.', '<|im_end|>', 'Ċ', '<|im_start|>', 'assistant', 'Ċ', 'Let', 'Ġme', 'Ġsolve', 'Ġthis', 'Ġstep', 'Ġby', 'Ġstep', '.Ċ', '<th', 'ink', '>'], ['<|im_start|>', 'system', 'Ċ', 'You', 'Ġare', 'Ġa', 'Ġhelpful', 'Ġassistant', '.', 'ĠYou', 'Ġfirst', 'Ġthink', 'Ġabout', 'Ġthe', 'Ġreasoning', 'Ġprocess', 'Ġin', 'Ġyour', 'Ġmind', 'Ġand', 'Ġthen', 'Ġprovide', 'Ġthe', 'Ġuser', 'Ġwith', 'Ġthe', 'Ġanswer', '.', '<|im_end|>', 'Ċ', '<|im_start|>', 'user', 'Ċ', 'Using', 'Ġthe', 'Ġnumbers', 'Ġ[', '8', '0', 'Ġ', '5', '2', 'Ġ', '9', '3', 'Ġ', 'Ġ', '7', '],', 'Ġcreate', 'Ġan', 'Ġequation', 'Ġthat', 'Ġequals', 'Ġ', '6', '5', '.', 'ĠYou', 'Ġcan', 'Ġuse', 'Ġbasic', 'Ġarithmetic', 'Ġoperations', 'Ġ(+', ',', 'Ġ-,', 'Ġ*,', 'Ġ/', ')', 'Ġand', 'Ġeach', 'Ġnumber', 'Ġcan', 'Ġonly', 'Ġbe', 'Ġused', 'Ġonce', '.', 'ĠShow', 'Ġyour', 'Ġwork', 'Ġin', 'Ġ<', 'think', '>', 'Ġ</', 'think', '>', 'Ġtags', '.', 'ĠAnd', 'Ġreturn', 'Ġthe', 'Ġfinal', 'Ġanswer', 'Ġin', 'Ġ<', 'answer', '>', 'Ġ</', 'answer', '>', 'Ġtags', ',', 'Ġfor', 'Ġexample', 'Ġ<', 'answer', '>', 'Ġ(', '1', 'Ġ+', 'Ġ', '2', ')', 'Ġ/', 'Ġ', '3', 'Ġ</', 'answer', '>.', '<|im_end|>', 'Ċ', '<|im_start|>', 'assistant', 'Ċ', 'Let', 'Ġme', 'Ġsolve', 'Ġthis', 'Ġstep', 'Ġby', 'Ġstep', '.Ċ', '<th', 'ink', '>'], ['<|im_start|>', 'system', 'Ċ', 'You', 'Ġare', 'Ġa', 'Ġhelpful', 'Ġassistant', '.', 'ĠYou', 'Ġfirst', 'Ġthink', 'Ġabout', 'Ġthe', 'Ġreasoning', 'Ġprocess', 'Ġin', 'Ġyour', 'Ġmind', 'Ġand', 'Ġthen', 'Ġprovide', 'Ġthe', 'Ġuser', 'Ġwith', 'Ġthe', 'Ġanswer', '.', '<|im_end|>', 'Ċ', '<|im_start|>', 'user', 'Ċ', 'Using', 'Ġthe', 'Ġnumbers', 'Ġ[', '7', '2', 'Ġ', '6', '7', 'Ġ', '4', '1', '],', 'Ġcreate', 'Ġan', 'Ġequation', 'Ġthat', 'Ġequals', 'Ġ', '9', '8', '.', 'ĠYou', 'Ġcan', 'Ġuse', 'Ġbasic', 'Ġarithmetic', 'Ġoperations', 'Ġ(+', ',', 'Ġ-,', 'Ġ*,', 'Ġ/', ')', 'Ġand', 'Ġeach', 'Ġnumber', 'Ġcan', 'Ġonly', 'Ġbe', 'Ġused', 'Ġonce', '.', 'ĠShow', 'Ġyour', 'Ġwork', 'Ġin', 'Ġ<', 'think', '>', 'Ġ</', 'think', '>', 'Ġtags', '.', 'ĠAnd', 'Ġreturn', 'Ġthe', 'Ġfinal', 'Ġanswer', 'Ġin', 'Ġ<', 'answer', '>', 'Ġ</', 'answer', '>', 'Ġtags', ',', 'Ġfor', 'Ġexample', 'Ġ<', 'answer', '>', 'Ġ(', '1', 'Ġ+', 'Ġ', '2', ')', 'Ġ/', 'Ġ', '3', 'Ġ</', 'answer', '>.', '<|im_end|>', 'Ċ', '<|im_start|>', 'assistant', 'Ċ', 'Let', 'Ġme', 'Ġsolve', 'Ġthis', 'Ġstep', 'Ġby', 'Ġstep', '.Ċ', '<th', 'ink', '>'], ['<|im_start|>', 'system', 'Ċ', 'You', 'Ġare', 'Ġa', 'Ġhelpful', 'Ġassistant', '.', 'ĠYou', 'Ġfirst', 'Ġthink', 'Ġabout', 'Ġthe', 'Ġreasoning', 'Ġprocess', 'Ġin', 'Ġyour', 'Ġmind', 'Ġand', 'Ġthen', 'Ġprovide', 'Ġthe', 'Ġuser', 'Ġwith', 'Ġthe', 'Ġanswer', '.', '<|im_end|>', 'Ċ', '<|im_start|>', 'user', 'Ċ', 'Using', 'Ġthe', 'Ġnumbers', 'Ġ[', '1', '0', 'Ġ', 'Ġ', '5', 'Ġ', '9', '8', '],', 'Ġcreate', 'Ġan', 'Ġequation', 'Ġthat', 'Ġequals', 'Ġ', '4', '9', '.', 'ĠYou', 'Ġcan', 'Ġuse', 'Ġbasic', 'Ġarithmetic', 'Ġoperations', 'Ġ(+', ',', 'Ġ-,', 'Ġ*,', 'Ġ/', ')', 'Ġand', 'Ġeach', 'Ġnumber', 'Ġcan', 'Ġonly', 'Ġbe', 'Ġused', 'Ġonce', '.', 'ĠShow', 'Ġyour', 'Ġwork', 'Ġin', 'Ġ<', 'think', '>', 'Ġ</', 'think', '>', 'Ġtags', '.', 'ĠAnd', 'Ġreturn', 'Ġthe', 'Ġfinal', 'Ġanswer', 'Ġin', 'Ġ<', 'answer', '>', 'Ġ</', 'answer', '>', 'Ġtags', ',', 'Ġfor', 'Ġexample', 'Ġ<', 'answer', '>', 'Ġ(', '1', 'Ġ+', 'Ġ', '2', ')', 'Ġ/', 'Ġ', '3', 'Ġ</', 'answer', '>.', '<|im_end|>', 'Ċ', '<|im_start|>', 'assistant', 'Ċ', 'Let', 'Ġme', 'Ġsolve', 'Ġthis', 'Ġstep', 'Ġby', 'Ġstep', '.Ċ', '<th', 'ink', '>'], ['<|im_start|>', 'system', 'Ċ', 'You', 'Ġare', 'Ġa', 'Ġhelpful', 'Ġassistant', '.', 'ĠYou', 'Ġfirst', 'Ġthink', 'Ġabout', 'Ġthe', 'Ġreasoning', 'Ġprocess', 'Ġin', 'Ġyour', 'Ġmind', 'Ġand', 'Ġthen', 'Ġprovide', 'Ġthe', 'Ġuser', 'Ġwith', 'Ġthe', 'Ġanswer', '.', '<|im_end|>', 'Ċ', '<|im_start|>', 'user', 'Ċ', 'Using', 'Ġthe', 'Ġnumbers', 'Ġ[', '5', '5', 'Ġ', '9', '8', 'Ġ', 'Ġ', '7', '],', 'Ġcreate', 'Ġan', 'Ġequation', 'Ġthat', 'Ġequals', 'Ġ', '5', '0', '.', 'ĠYou', 'Ġcan', 'Ġuse', 'Ġbasic', 'Ġarithmetic', 'Ġoperations', 'Ġ(+', ',', 'Ġ-,', 'Ġ*,', 'Ġ/', ')', 'Ġand', 'Ġeach', 'Ġnumber', 'Ġcan', 'Ġonly', 'Ġbe', 'Ġused', 'Ġonce', '.', 'ĠShow', 'Ġyour', 'Ġwork', 'Ġin', 'Ġ<', 'think', '>', 'Ġ</', 'think', '>', 'Ġtags', '.', 'ĠAnd', 'Ġreturn', 'Ġthe', 'Ġfinal', 'Ġanswer', 'Ġin', 'Ġ<', 'answer', '>', 'Ġ</', 'answer', '>', 'Ġtags', ',', 'Ġfor', 'Ġexample', 'Ġ<', 'answer', '>', 'Ġ(', '1', 'Ġ+', 'Ġ', '2', ')', 'Ġ/', 'Ġ', '3', 'Ġ</', 'answer', '>.', '<|im_end|>', 'Ċ', '<|im_start|>', 'assistant', 'Ċ', 'Let', 'Ġme', 'Ġsolve', 'Ġthis', 'Ġstep', 'Ġby', 'Ġstep', '.Ċ', '<th', 'ink', '>'], ['<|im_start|>', 'system', 'Ċ', 'You', 'Ġare', 'Ġa', 'Ġhelpful', 'Ġassistant', '.', 'ĠYou', 'Ġfirst', 'Ġthink', 'Ġabout', 'Ġthe', 'Ġreasoning', 'Ġprocess', 'Ġin', 'Ġyour', 'Ġmind', 'Ġand', 'Ġthen', 'Ġprovide', 'Ġthe', 'Ġuser', 'Ġwith', 'Ġthe', 'Ġanswer', '.', '<|im_end|>', 'Ċ', '<|im_start|>', 'user', 'Ċ', 'Using', 'Ġthe', 'Ġnumbers', 'Ġ[', '1', '9', 'Ġ', '5', '0', 'Ġ', '6', '0', '],', 'Ġcreate', 'Ġan', 'Ġequation', 'Ġthat', 'Ġequals', 'Ġ', '2', '9', '.', 'ĠYou', 'Ġcan', 'Ġuse', 'Ġbasic', 'Ġarithmetic', 'Ġoperations', 'Ġ(+', ',', 'Ġ-,', 'Ġ*,', 'Ġ/', ')', 'Ġand', 'Ġeach', 'Ġnumber', 'Ġcan', 'Ġonly', 'Ġbe', 'Ġused', 'Ġonce', '.', 'ĠShow', 'Ġyour', 'Ġwork', 'Ġin', 'Ġ<', 'think', '>', 'Ġ</', 'think', '>', 'Ġtags', '.', 'ĠAnd', 'Ġreturn', 'Ġthe', 'Ġfinal', 'Ġanswer', 'Ġin', 'Ġ<', 'answer', '>', 'Ġ</', 'answer', '>', 'Ġtags', ',', 'Ġfor', 'Ġexample', 'Ġ<', 'answer', '>', 'Ġ(', '1', 'Ġ+', 'Ġ', '2', ')', 'Ġ/', 'Ġ', '3', 'Ġ</', 'answer', '>.', '<|im_end|>', 'Ċ', '<|im_start|>', 'assistant', 'Ċ', 'Let', 'Ġme', 'Ġsolve', 'Ġthis', 'Ġstep', 'Ġby', 'Ġstep', '.Ċ', '<th', 'ink', '>'], ['<|im_start|>', 'system', 'Ċ', 'You', 'Ġare', 'Ġa', 'Ġhelpful', 'Ġassistant', '.', 'ĠYou', 'Ġfirst', 'Ġthink', 'Ġabout', 'Ġthe', 'Ġreasoning', 'Ġprocess', 'Ġin', 'Ġyour', 'Ġmind', 'Ġand', 'Ġthen', 'Ġprovide', 'Ġthe', 'Ġuser', 'Ġwith', 'Ġthe', 'Ġanswer', '.', '<|im_end|>', 'Ċ', '<|im_start|>', 'user', 'Ċ', 'Using', 'Ġthe', 'Ġnumbers', 'Ġ[', '1', '2', 'Ġ', '8', '4', 'Ġ', '4', '2', 'Ġ', '2', '0', '],', 'Ġcreate', 'Ġan', 'Ġequation', 'Ġthat', 'Ġequals', 'Ġ', '5', '0', '.', 'ĠYou', 'Ġcan', 'Ġuse', 'Ġbasic', 'Ġarithmetic', 'Ġoperations', 'Ġ(+', ',', 'Ġ-,', 'Ġ*,', 'Ġ/', ')', 'Ġand', 'Ġeach', 'Ġnumber', 'Ġcan', 'Ġonly', 'Ġbe', 'Ġused', 'Ġonce', '.', 'ĠShow', 'Ġyour', 'Ġwork', 'Ġin', 'Ġ<', 'think', '>', 'Ġ</', 'think', '>', 'Ġtags', '.', 'ĠAnd', 'Ġreturn', 'Ġthe', 'Ġfinal', 'Ġanswer', 'Ġin', 'Ġ<', 'answer', '>', 'Ġ</', 'answer', '>', 'Ġtags', ',', 'Ġfor', 'Ġexample', 'Ġ<', 'answer', '>', 'Ġ(', '1', 'Ġ+', 'Ġ', '2', ')', 'Ġ/', 'Ġ', '3', 'Ġ</', 'answer', '>.', '<|im_end|>', 'Ċ', '<|im_start|>', 'assistant', 'Ċ', 'Let', 'Ġme', 'Ġsolve', 'Ġthis', 'Ġstep', 'Ġby', 'Ġstep', '.Ċ', '<th', 'ink', '>'], ['<|im_start|>', 'system', 'Ċ', 'You', 'Ġare', 'Ġa', 'Ġhelpful', 'Ġassistant', '.', 'ĠYou', 'Ġfirst', 'Ġthink', 'Ġabout', 'Ġthe', 'Ġreasoning', 'Ġprocess', 'Ġin', 'Ġyour', 'Ġmind', 'Ġand', 'Ġthen', 'Ġprovide', 'Ġthe', 'Ġuser', 'Ġwith', 'Ġthe', 'Ġanswer', '.', '<|im_end|>', 'Ċ', '<|im_start|>', 'user', 'Ċ', 'Using', 'Ġthe', 'Ġnumbers', 'Ġ[', '4', '4', 'Ġ', '3', '0', 'Ġ', '3', '9', 'Ġ', 'Ġ', '3', '],', 'Ġcreate', 'Ġan', 'Ġequation', 'Ġthat', 'Ġequals', 'Ġ', '6', '7', '.', 'ĠYou', 'Ġcan', 'Ġuse', 'Ġbasic', 'Ġarithmetic', 'Ġoperations', 'Ġ(+', ',', 'Ġ-,', 'Ġ*,', 'Ġ/', ')', 'Ġand', 'Ġeach', 'Ġnumber', 'Ġcan', 'Ġonly', 'Ġbe', 'Ġused', 'Ġonce', '.', 'ĠShow', 'Ġyour', 'Ġwork', 'Ġin', 'Ġ<', 'think', '>', 'Ġ</', 'think', '>', 'Ġtags', '.', 'ĠAnd', 'Ġreturn', 'Ġthe', 'Ġfinal', 'Ġanswer', 'Ġin', 'Ġ<', 'answer', '>', 'Ġ</', 'answer', '>', 'Ġtags', ',', 'Ġfor', 'Ġexample', 'Ġ<', 'answer', '>', 'Ġ(', '1', 'Ġ+', 'Ġ', '2', ')', 'Ġ/', 'Ġ', '3', 'Ġ</', 'answer', '>.', '<|im_end|>', 'Ċ', '<|im_start|>', 'assistant', 'Ċ', 'Let', 'Ġme', 'Ġsolve', 'Ġthis', 'Ġstep', 'Ġby', 'Ġstep', '.Ċ', '<th', 'ink', '>'], ['<|im_start|>', 'system', 'Ċ', 'You', 'Ġare', 'Ġa', 'Ġhelpful', 'Ġassistant', '.', 'ĠYou', 'Ġfirst', 'Ġthink', 'Ġabout', 'Ġthe', 'Ġreasoning', 'Ġprocess', 'Ġin', 'Ġyour', 'Ġmind', 'Ġand', 'Ġthen', 'Ġprovide', 'Ġthe', 'Ġuser', 'Ġwith', 'Ġthe', 'Ġanswer', '.', '<|im_end|>', 'Ċ', '<|im_start|>', 'user', 'Ċ', 'Using', 'Ġthe', 'Ġnumbers', 'Ġ[', '4', '6', 'Ġ', '5', '5', 'Ġ', '3', '5', '],', 'Ġcreate', 'Ġan', 'Ġequation', 'Ġthat', 'Ġequals', 'Ġ', '2', '6', '.', 'ĠYou', 'Ġcan', 'Ġuse', 'Ġbasic', 'Ġarithmetic', 'Ġoperations', 'Ġ(+', ',', 'Ġ-,', 'Ġ*,', 'Ġ/', ')', 'Ġand', 'Ġeach', 'Ġnumber', 'Ġcan', 'Ġonly', 'Ġbe', 'Ġused', 'Ġonce', '.', 'ĠShow', 'Ġyour', 'Ġwork', 'Ġin', 'Ġ<', 'think', '>', 'Ġ</', 'think', '>', 'Ġtags', '.', 'ĠAnd', 'Ġreturn', 'Ġthe', 'Ġfinal', 'Ġanswer', 'Ġin', 'Ġ<', 'answer', '>', 'Ġ</', 'answer', '>', 'Ġtags', ',', 'Ġfor', 'Ġexample', 'Ġ<', 'answer', '>', 'Ġ(', '1', 'Ġ+', 'Ġ', '2', ')', 'Ġ/', 'Ġ', '3', 'Ġ</', 'answer', '>.', '<|im_end|>', 'Ċ', '<|im_start|>', 'assistant', 'Ċ', 'Let', 'Ġme', 'Ġsolve', 'Ġthis', 'Ġstep', 'Ġby', 'Ġstep', '.Ċ', '<th', 'ink', '>'], ['<|im_start|>', 'system', 'Ċ', 'You', 'Ġare', 'Ġa', 'Ġhelpful', 'Ġassistant', '.', 'ĠYou', 'Ġfirst', 'Ġthink', 'Ġabout', 'Ġthe', 'Ġreasoning', 'Ġprocess', 'Ġin', 'Ġyour', 'Ġmind', 'Ġand', 'Ġthen', 'Ġprovide', 'Ġthe', 'Ġuser', 'Ġwith', 'Ġthe', 'Ġanswer', '.', '<|im_end|>', 'Ċ', '<|im_start|>', 'user', 'Ċ', 'Using', 'Ġthe', 'Ġnumbers', 'Ġ[', '6', '9', 'Ġ', '2', '0', 'Ġ', '6', '8', 'Ġ', '3', '6', '],', 'Ġcreate', 'Ġan', 'Ġequation', 'Ġthat', 'Ġequals', 'Ġ', '9', '2', '.', 'ĠYou', 'Ġcan', 'Ġuse', 'Ġbasic', 'Ġarithmetic', 'Ġoperations', 'Ġ(+', ',', 'Ġ-,', 'Ġ*,', 'Ġ/', ')', 'Ġand', 'Ġeach', 'Ġnumber', 'Ġcan', 'Ġonly', 'Ġbe', 'Ġused', 'Ġonce', '.', 'ĠShow', 'Ġyour', 'Ġwork', 'Ġin', 'Ġ<', 'think', '>', 'Ġ</', 'think', '>', 'Ġtags', '.', 'ĠAnd', 'Ġreturn', 'Ġthe', 'Ġfinal', 'Ġanswer', 'Ġin', 'Ġ<', 'answer', '>', 'Ġ</', 'answer', '>', 'Ġtags', ',', 'Ġfor', 'Ġexample', 'Ġ<', 'answer', '>', 'Ġ(', '1', 'Ġ+', 'Ġ', '2', ')', 'Ġ/', 'Ġ', '3', 'Ġ</', 'answer', '>.', '<|im_end|>', 'Ċ', '<|im_start|>', 'assistant', 'Ċ', 'Let', 'Ġme', 'Ġsolve', 'Ġthis', 'Ġstep', 'Ġby', 'Ġstep', '.Ċ', '<th', 'ink', '>'], ['<|im_start|>', 'system', 'Ċ', 'You', 'Ġare', 'Ġa', 'Ġhelpful', 'Ġassistant', '.', 'ĠYou', 'Ġfirst', 'Ġthink', 'Ġabout', 'Ġthe', 'Ġreasoning', 'Ġprocess', 'Ġin', 'Ġyour', 'Ġmind', 'Ġand', 'Ġthen', 'Ġprovide', 'Ġthe', 'Ġuser', 'Ġwith', 'Ġthe', 'Ġanswer', '.', '<|im_end|>', 'Ċ', '<|im_start|>', 'user', 'Ċ', 'Using', 'Ġthe', 'Ġnumbers', 'Ġ[', '6', '2', 'Ġ', '8', '9', 'Ġ', 'Ġ', '3', 'Ġ', '6', '1', '],', 'Ġcreate', 'Ġan', 'Ġequation', 'Ġthat', 'Ġequals', 'Ġ', '3', '7', '.', 'ĠYou', 'Ġcan', 'Ġuse', 'Ġbasic', 'Ġarithmetic', 'Ġoperations', 'Ġ(+', ',', 'Ġ-,', 'Ġ*,', 'Ġ/', ')', 'Ġand', 'Ġeach', 'Ġnumber', 'Ġcan', 'Ġonly', 'Ġbe', 'Ġused', 'Ġonce', '.', 'ĠShow', 'Ġyour', 'Ġwork', 'Ġin', 'Ġ<', 'think', '>', 'Ġ</', 'think', '>', 'Ġtags', '.', 'ĠAnd', 'Ġreturn', 'Ġthe', 'Ġfinal', 'Ġanswer', 'Ġin', 'Ġ<', 'answer', '>', 'Ġ</', 'answer', '>', 'Ġtags', ',', 'Ġfor', 'Ġexample', 'Ġ<', 'answer', '>', 'Ġ(', '1', 'Ġ+', 'Ġ', '2', ')', 'Ġ/', 'Ġ', '3', 'Ġ</', 'answer', '>.', '<|im_end|>', 'Ċ', '<|im_start|>', 'assistant', 'Ċ', 'Let', 'Ġme', 'Ġsolve', 'Ġthis', 'Ġstep', 'Ġby', 'Ġstep', '.Ċ', '<th', 'ink', '>'], ['<|im_start|>', 'system', 'Ċ', 'You', 'Ġare', 'Ġa', 'Ġhelpful', 'Ġassistant', '.', 'ĠYou', 'Ġfirst', 'Ġthink', 'Ġabout', 'Ġthe', 'Ġreasoning', 'Ġprocess', 'Ġin', 'Ġyour', 'Ġmind', 'Ġand', 'Ġthen', 'Ġprovide', 'Ġthe', 'Ġuser', 'Ġwith', 'Ġthe', 'Ġanswer', '.', '<|im_end|>', 'Ċ', '<|im_start|>', 'user', 'Ċ', 'Using', 'Ġthe', 'Ġnumbers', 'Ġ[', '2', '1', 'Ġ', '1', '0', 'Ġ', 'Ġ', '6', 'Ġ', '3', '6', '],', 'Ġcreate', 'Ġan', 'Ġequation', 'Ġthat', 'Ġequals', 'Ġ', '2', '0', '.', 'ĠYou', 'Ġcan', 'Ġuse', 'Ġbasic', 'Ġarithmetic', 'Ġoperations', 'Ġ(+', ',', 'Ġ-,', 'Ġ*,', 'Ġ/', ')', 'Ġand', 'Ġeach', 'Ġnumber', 'Ġcan', 'Ġonly', 'Ġbe', 'Ġused', 'Ġonce', '.', 'ĠShow', 'Ġyour', 'Ġwork', 'Ġin', 'Ġ<', 'think', '>', 'Ġ</', 'think', '>', 'Ġtags', '.', 'ĠAnd', 'Ġreturn', 'Ġthe', 'Ġfinal', 'Ġanswer', 'Ġin', 'Ġ<', 'answer', '>', 'Ġ</', 'answer', '>', 'Ġtags', ',', 'Ġfor', 'Ġexample', 'Ġ<', 'answer', '>', 'Ġ(', '1', 'Ġ+', 'Ġ', '2', ')', 'Ġ/', 'Ġ', '3', 'Ġ</', 'answer', '>.', '<|im_end|>', 'Ċ', '<|im_start|>', 'assistant', 'Ċ', 'Let', 'Ġme', 'Ġsolve', 'Ġthis', 'Ġstep', 'Ġby', 'Ġstep', '.Ċ', '<th', 'ink', '>'], ['<|im_start|>', 'system', 'Ċ', 'You', 'Ġare', 'Ġa', 'Ġhelpful', 'Ġassistant', '.', 'ĠYou', 'Ġfirst', 'Ġthink', 'Ġabout', 'Ġthe', 'Ġreasoning', 'Ġprocess', 'Ġin', 'Ġyour', 'Ġmind', 'Ġand', 'Ġthen', 'Ġprovide', 'Ġthe', 'Ġuser', 'Ġwith', 'Ġthe', 'Ġanswer', '.', '<|im_end|>', 'Ċ', '<|im_start|>', 'user', 'Ċ', 'Using', 'Ġthe', 'Ġnumbers', 'Ġ[', '9', '9', 'Ġ', '7', '5', 'Ġ', '6', '6', 'Ġ', 'Ġ', '5', '],', 'Ġcreate', 'Ġan', 'Ġequation', 'Ġthat', 'Ġequals', 'Ġ', '1', '6', '.', 'ĠYou', 'Ġcan', 'Ġuse', 'Ġbasic', 'Ġarithmetic', 'Ġoperations', 'Ġ(+', ',', 'Ġ-,', 'Ġ*,', 'Ġ/', ')', 'Ġand', 'Ġeach', 'Ġnumber', 'Ġcan', 'Ġonly', 'Ġbe', 'Ġused', 'Ġonce', '.', 'ĠShow', 'Ġyour', 'Ġwork', 'Ġin', 'Ġ<', 'think', '>', 'Ġ</', 'think', '>', 'Ġtags', '.', 'ĠAnd', 'Ġreturn', 'Ġthe', 'Ġfinal', 'Ġanswer', 'Ġin', 'Ġ<', 'answer', '>', 'Ġ</', 'answer', '>', 'Ġtags', ',', 'Ġfor', 'Ġexample', 'Ġ<', 'answer', '>', 'Ġ(', '1', 'Ġ+', 'Ġ', '2', ')', 'Ġ/', 'Ġ', '3', 'Ġ</', 'answer', '>.', '<|im_end|>', 'Ċ', '<|im_start|>', 'assistant', 'Ċ', 'Let', 'Ġme', 'Ġsolve', 'Ġthis', 'Ġstep', 'Ġby', 'Ġstep', '.Ċ', '<th', 'ink', '>'], ['<|im_start|>', 'system', 'Ċ', 'You', 'Ġare', 'Ġa', 'Ġhelpful', 'Ġassistant', '.', 'ĠYou', 'Ġfirst', 'Ġthink', 'Ġabout', 'Ġthe', 'Ġreasoning', 'Ġprocess', 'Ġin', 'Ġyour', 'Ġmind', 'Ġand', 'Ġthen', 'Ġprovide', 'Ġthe', 'Ġuser', 'Ġwith', 'Ġthe', 'Ġanswer', '.', '<|im_end|>', 'Ċ', '<|im_start|>', 'user', 'Ċ', 'Using', 'Ġthe', 'Ġnumbers', 'Ġ[', '1', '1', 'Ġ', '8', '4', 'Ġ', '6', '5', '],', 'Ġcreate', 'Ġan', 'Ġequation', 'Ġthat', 'Ġequals', 'Ġ', '3', '0', '.', 'ĠYou', 'Ġcan', 'Ġuse', 'Ġbasic', 'Ġarithmetic', 'Ġoperations', 'Ġ(+', ',', 'Ġ-,', 'Ġ*,', 'Ġ/', ')', 'Ġand', 'Ġeach', 'Ġnumber', 'Ġcan', 'Ġonly', 'Ġbe', 'Ġused', 'Ġonce', '.', 'ĠShow', 'Ġyour', 'Ġwork', 'Ġin', 'Ġ<', 'think', '>', 'Ġ</', 'think', '>', 'Ġtags', '.', 'ĠAnd', 'Ġreturn', 'Ġthe', 'Ġfinal', 'Ġanswer', 'Ġin', 'Ġ<', 'answer', '>', 'Ġ</', 'answer', '>', 'Ġtags', ',', 'Ġfor', 'Ġexample', 'Ġ<', 'answer', '>', 'Ġ(', '1', 'Ġ+', 'Ġ', '2', ')', 'Ġ/', 'Ġ', '3', 'Ġ</', 'answer', '>.', '<|im_end|>', 'Ċ', '<|im_start|>', 'assistant', 'Ċ', 'Let', 'Ġme', 'Ġsolve', 'Ġthis', 'Ġstep', 'Ġby', 'Ġstep', '.Ċ', '<th', 'ink', '>'], ['<|im_start|>', 'system', 'Ċ', 'You', 'Ġare', 'Ġa', 'Ġhelpful', 'Ġassistant', '.', 'ĠYou', 'Ġfirst', 'Ġthink', 'Ġabout', 'Ġthe', 'Ġreasoning', 'Ġprocess', 'Ġin', 'Ġyour', 'Ġmind', 'Ġand', 'Ġthen', 'Ġprovide', 'Ġthe', 'Ġuser', 'Ġwith', 'Ġthe', 'Ġanswer', '.', '<|im_end|>', 'Ċ', '<|im_start|>', 'user', 'Ċ', 'Using', 'Ġthe', 'Ġnumbers', 'Ġ[', '2', '8', 'Ġ', '5', '9', 'Ġ', '3', '5', '],', 'Ġcreate', 'Ġan', 'Ġequation', 'Ġthat', 'Ġequals', 'Ġ', '5', '2', '.', 'ĠYou', 'Ġcan', 'Ġuse', 'Ġbasic', 'Ġarithmetic', 'Ġoperations', 'Ġ(+', ',', 'Ġ-,', 'Ġ*,', 'Ġ/', ')', 'Ġand', 'Ġeach', 'Ġnumber', 'Ġcan', 'Ġonly', 'Ġbe', 'Ġused', 'Ġonce', '.', 'ĠShow', 'Ġyour', 'Ġwork', 'Ġin', 'Ġ<', 'think', '>', 'Ġ</', 'think', '>', 'Ġtags', '.', 'ĠAnd', 'Ġreturn', 'Ġthe', 'Ġfinal', 'Ġanswer', 'Ġin', 'Ġ<', 'answer', '>', 'Ġ</', 'answer', '>', 'Ġtags', ',', 'Ġfor', 'Ġexample', 'Ġ<', 'answer', '>', 'Ġ(', '1', 'Ġ+', 'Ġ', '2', ')', 'Ġ/', 'Ġ', '3', 'Ġ</', 'answer', '>.', '<|im_end|>', 'Ċ', '<|im_start|>', 'assistant', 'Ċ', 'Let', 'Ġme', 'Ġsolve', 'Ġthis', 'Ġstep', 'Ġby', 'Ġstep', '.Ċ', '<th', 'ink', '>'], ['<|im_start|>', 'system', 'Ċ', 'You', 'Ġare', 'Ġa', 'Ġhelpful', 'Ġassistant', '.', 'ĠYou', 'Ġfirst', 'Ġthink', 'Ġabout', 'Ġthe', 'Ġreasoning', 'Ġprocess', 'Ġin', 'Ġyour', 'Ġmind', 'Ġand', 'Ġthen', 'Ġprovide', 'Ġthe', 'Ġuser', 'Ġwith', 'Ġthe', 'Ġanswer', '.', '<|im_end|>', 'Ċ', '<|im_start|>', 'user', 'Ċ', 'Using', 'Ġthe', 'Ġnumbers', 'Ġ[', '6', '0', 'Ġ', '4', '7', 'Ġ', 'Ġ', '4', 'Ġ', '1', '2', '],', 'Ġcreate', 'Ġan', 'Ġequation', 'Ġthat', 'Ġequals', 'Ġ', '5', '9', '.', 'ĠYou', 'Ġcan', 'Ġuse', 'Ġbasic', 'Ġarithmetic', 'Ġoperations', 'Ġ(+', ',', 'Ġ-,', 'Ġ*,', 'Ġ/', ')', 'Ġand', 'Ġeach', 'Ġnumber', 'Ġcan', 'Ġonly', 'Ġbe', 'Ġused', 'Ġonce', '.', 'ĠShow', 'Ġyour', 'Ġwork', 'Ġin', 'Ġ<', 'think', '>', 'Ġ</', 'think', '>', 'Ġtags', '.', 'ĠAnd', 'Ġreturn', 'Ġthe', 'Ġfinal', 'Ġanswer', 'Ġin', 'Ġ<', 'answer', '>', 'Ġ</', 'answer', '>', 'Ġtags', ',', 'Ġfor', 'Ġexample', 'Ġ<', 'answer', '>', 'Ġ(', '1', 'Ġ+', 'Ġ', '2', ')', 'Ġ/', 'Ġ', '3', 'Ġ</', 'answer', '>.', '<|im_end|>', 'Ċ', '<|im_start|>', 'assistant', 'Ċ', 'Let', 'Ġme', 'Ġsolve', 'Ġthis', 'Ġstep', 'Ġby', 'Ġstep', '.Ċ', '<th', 'ink', '>'], ['<|im_start|>', 'system', 'Ċ', 'You', 'Ġare', 'Ġa', 'Ġhelpful', 'Ġassistant', '.', 'ĠYou', 'Ġfirst', 'Ġthink', 'Ġabout', 'Ġthe', 'Ġreasoning', 'Ġprocess', 'Ġin', 'Ġyour', 'Ġmind', 'Ġand', 'Ġthen', 'Ġprovide', 'Ġthe', 'Ġuser', 'Ġwith', 'Ġthe', 'Ġanswer', '.', '<|im_end|>', 'Ċ', '<|im_start|>', 'user', 'Ċ', 'Using', 'Ġthe', 'Ġnumbers', 'Ġ[', '2', '1', 'Ġ', '9', '0', 'Ġ', '7', '5', 'Ġ', '3', '2', '],', 'Ġcreate', 'Ġan', 'Ġequation', 'Ġthat', 'Ġequals', 'Ġ', '9', '3', '.', 'ĠYou', 'Ġcan', 'Ġuse', 'Ġbasic', 'Ġarithmetic', 'Ġoperations', 'Ġ(+', ',', 'Ġ-,', 'Ġ*,', 'Ġ/', ')', 'Ġand', 'Ġeach', 'Ġnumber', 'Ġcan', 'Ġonly', 'Ġbe', 'Ġused', 'Ġonce', '.', 'ĠShow', 'Ġyour', 'Ġwork', 'Ġin', 'Ġ<', 'think', '>', 'Ġ</', 'think', '>', 'Ġtags', '.', 'ĠAnd', 'Ġreturn', 'Ġthe', 'Ġfinal', 'Ġanswer', 'Ġin', 'Ġ<', 'answer', '>', 'Ġ</', 'answer', '>', 'Ġtags', ',', 'Ġfor', 'Ġexample', 'Ġ<', 'answer', '>', 'Ġ(', '1', 'Ġ+', 'Ġ', '2', ')', 'Ġ/', 'Ġ', '3', 'Ġ</', 'answer', '>.', '<|im_end|>', 'Ċ', '<|im_start|>', 'assistant', 'Ċ', 'Let', 'Ġme', 'Ġsolve', 'Ġthis', 'Ġstep', 'Ġby', 'Ġstep', '.Ċ', '<th', 'ink', '>'], ['<|im_start|>', 'system', 'Ċ', 'You', 'Ġare', 'Ġa', 'Ġhelpful', 'Ġassistant', '.', 'ĠYou', 'Ġfirst', 'Ġthink', 'Ġabout', 'Ġthe', 'Ġreasoning', 'Ġprocess', 'Ġin', 'Ġyour', 'Ġmind', 'Ġand', 'Ġthen', 'Ġprovide', 'Ġthe', 'Ġuser', 'Ġwith', 'Ġthe', 'Ġanswer', '.', '<|im_end|>', 'Ċ', '<|im_start|>', 'user', 'Ċ', 'Using', 'Ġthe', 'Ġnumbers', 'Ġ[', '4', '8', 'Ġ', '6', '0', 'Ġ', '6', '4', 'Ġ', '9', '6', '],', 'Ġcreate', 'Ġan', 'Ġequation', 'Ġthat', 'Ġequals', 'Ġ', '7', '8', '.', 'ĠYou', 'Ġcan', 'Ġuse', 'Ġbasic', 'Ġarithmetic', 'Ġoperations', 'Ġ(+', ',', 'Ġ-,', 'Ġ*,', 'Ġ/', ')', 'Ġand', 'Ġeach', 'Ġnumber', 'Ġcan', 'Ġonly', 'Ġbe', 'Ġused', 'Ġonce', '.', 'ĠShow', 'Ġyour', 'Ġwork', 'Ġin', 'Ġ<', 'think', '>', 'Ġ</', 'think', '>', 'Ġtags', '.', 'ĠAnd', 'Ġreturn', 'Ġthe', 'Ġfinal', 'Ġanswer', 'Ġin', 'Ġ<', 'answer', '>', 'Ġ</', 'answer', '>', 'Ġtags', ',', 'Ġfor', 'Ġexample', 'Ġ<', 'answer', '>', 'Ġ(', '1', 'Ġ+', 'Ġ', '2', ')', 'Ġ/', 'Ġ', '3', 'Ġ</', 'answer', '>.', '<|im_end|>', 'Ċ', '<|im_start|>', 'assistant', 'Ċ', 'Let', 'Ġme', 'Ġsolve', 'Ġthis', 'Ġstep', 'Ġby', 'Ġstep', '.Ċ', '<th', 'ink', '>'], ['<|im_start|>', 'system', 'Ċ', 'You', 'Ġare', 'Ġa', 'Ġhelpful', 'Ġassistant', '.', 'ĠYou', 'Ġfirst', 'Ġthink', 'Ġabout', 'Ġthe', 'Ġreasoning', 'Ġprocess', 'Ġin', 'Ġyour', 'Ġmind', 'Ġand', 'Ġthen', 'Ġprovide', 'Ġthe', 'Ġuser', 'Ġwith', 'Ġthe', 'Ġanswer', '.', '<|im_end|>', 'Ċ', '<|im_start|>', 'user', 'Ċ', 'Using', 'Ġthe', 'Ġnumbers', 'Ġ[', 'Ġ', '2', 'Ġ', '2', '0', 'Ġ', '3', '3', '],', 'Ġcreate', 'Ġan', 'Ġequation', 'Ġthat', 'Ġequals', 'Ġ', '5', '1', '.', 'ĠYou', 'Ġcan', 'Ġuse', 'Ġbasic', 'Ġarithmetic', 'Ġoperations', 'Ġ(+', ',', 'Ġ-,', 'Ġ*,', 'Ġ/', ')', 'Ġand', 'Ġeach', 'Ġnumber', 'Ġcan', 'Ġonly', 'Ġbe', 'Ġused', 'Ġonce', '.', 'ĠShow', 'Ġyour', 'Ġwork', 'Ġin', 'Ġ<', 'think', '>', 'Ġ</', 'think', '>', 'Ġtags', '.', 'ĠAnd', 'Ġreturn', 'Ġthe', 'Ġfinal', 'Ġanswer', 'Ġin', 'Ġ<', 'answer', '>', 'Ġ</', 'answer', '>', 'Ġtags', ',', 'Ġfor', 'Ġexample', 'Ġ<', 'answer', '>', 'Ġ(', '1', 'Ġ+', 'Ġ', '2', ')', 'Ġ/', 'Ġ', '3', 'Ġ</', 'answer', '>.', '<|im_end|>', 'Ċ', '<|im_start|>', 'assistant', 'Ċ', 'Let', 'Ġme', 'Ġsolve', 'Ġthis', 'Ġstep', 'Ġby', 'Ġstep', '.Ċ', '<th', 'ink', '>'], ['<|im_start|>', 'system', 'Ċ', 'You', 'Ġare', 'Ġa', 'Ġhelpful', 'Ġassistant', '.', 'ĠYou', 'Ġfirst', 'Ġthink', 'Ġabout', 'Ġthe', 'Ġreasoning', 'Ġprocess', 'Ġin', 'Ġyour', 'Ġmind', 'Ġand', 'Ġthen', 'Ġprovide', 'Ġthe', 'Ġuser', 'Ġwith', 'Ġthe', 'Ġanswer', '.', '<|im_end|>', 'Ċ', '<|im_start|>', 'user', 'Ċ', 'Using', 'Ġthe', 'Ġnumbers', 'Ġ[', '6', '8', 'Ġ', '3', '3', 'Ġ', '6', '5', 'Ġ', '1', '5', '],', 'Ġcreate', 'Ġan', 'Ġequation', 'Ġthat', 'Ġequals', 'Ġ', '7', '5', '.', 'ĠYou', 'Ġcan', 'Ġuse', 'Ġbasic', 'Ġarithmetic', 'Ġoperations', 'Ġ(+', ',', 'Ġ-,', 'Ġ*,', 'Ġ/', ')', 'Ġand', 'Ġeach', 'Ġnumber', 'Ġcan', 'Ġonly', 'Ġbe', 'Ġused', 'Ġonce', '.', 'ĠShow', 'Ġyour', 'Ġwork', 'Ġin', 'Ġ<', 'think', '>', 'Ġ</', 'think', '>', 'Ġtags', '.', 'ĠAnd', 'Ġreturn', 'Ġthe', 'Ġfinal', 'Ġanswer', 'Ġin', 'Ġ<', 'answer', '>', 'Ġ</', 'answer', '>', 'Ġtags', ',', 'Ġfor', 'Ġexample', 'Ġ<', 'answer', '>', 'Ġ(', '1', 'Ġ+', 'Ġ', '2', ')', 'Ġ/', 'Ġ', '3', 'Ġ</', 'answer', '>.', '<|im_end|>', 'Ċ', '<|im_start|>', 'assistant', 'Ċ', 'Let', 'Ġme', 'Ġsolve', 'Ġthis', 'Ġstep', 'Ġby', 'Ġstep', '.Ċ', '<th', 'ink', '>'], ['<|im_start|>', 'system', 'Ċ', 'You', 'Ġare', 'Ġa', 'Ġhelpful', 'Ġassistant', '.', 'ĠYou', 'Ġfirst', 'Ġthink', 'Ġabout', 'Ġthe', 'Ġreasoning', 'Ġprocess', 'Ġin', 'Ġyour', 'Ġmind', 'Ġand', 'Ġthen', 'Ġprovide', 'Ġthe', 'Ġuser', 'Ġwith', 'Ġthe', 'Ġanswer', '.', '<|im_end|>', 'Ċ', '<|im_start|>', 'user', 'Ċ', 'Using', 'Ġthe', 'Ġnumbers', 'Ġ[', '5', '7', 'Ġ', '6', '7', 'Ġ', 'Ġ', '7', 'Ġ', '1', '0', '],', 'Ġcreate', 'Ġan', 'Ġequation', 'Ġthat', 'Ġequals', 'Ġ', '6', '3', '.', 'ĠYou', 'Ġcan', 'Ġuse', 'Ġbasic', 'Ġarithmetic', 'Ġoperations', 'Ġ(+', ',', 'Ġ-,', 'Ġ*,', 'Ġ/', ')', 'Ġand', 'Ġeach', 'Ġnumber', 'Ġcan', 'Ġonly', 'Ġbe', 'Ġused', 'Ġonce', '.', 'ĠShow', 'Ġyour', 'Ġwork', 'Ġin', 'Ġ<', 'think', '>', 'Ġ</', 'think', '>', 'Ġtags', '.', 'ĠAnd', 'Ġreturn', 'Ġthe', 'Ġfinal', 'Ġanswer', 'Ġin', 'Ġ<', 'answer', '>', 'Ġ</', 'answer', '>', 'Ġtags', ',', 'Ġfor', 'Ġexample', 'Ġ<', 'answer', '>', 'Ġ(', '1', 'Ġ+', 'Ġ', '2', ')', 'Ġ/', 'Ġ', '3', 'Ġ</', 'answer', '>.', '<|im_end|>', 'Ċ', '<|im_start|>', 'assistant', 'Ċ', 'Let', 'Ġme', 'Ġsolve', 'Ġthis', 'Ġstep', 'Ġby', 'Ġstep', '.Ċ', '<th', 'ink', '>'], ['<|im_start|>', 'system', 'Ċ', 'You', 'Ġare', 'Ġa', 'Ġhelpful', 'Ġassistant', '.', 'ĠYou', 'Ġfirst', 'Ġthink', 'Ġabout', 'Ġthe', 'Ġreasoning', 'Ġprocess', 'Ġin', 'Ġyour', 'Ġmind', 'Ġand', 'Ġthen', 'Ġprovide', 'Ġthe', 'Ġuser', 'Ġwith', 'Ġthe', 'Ġanswer', '.', '<|im_end|>', 'Ċ', '<|im_start|>', 'user', 'Ċ', 'Using', 'Ġthe', 'Ġnumbers', 'Ġ[', '5', '2', 'Ġ', '1', '7', 'Ġ', '1', '9', 'Ġ', '2', '1', '],', 'Ġcreate', 'Ġan', 'Ġequation', 'Ġthat', 'Ġequals', 'Ġ', '8', '6', '.', 'ĠYou', 'Ġcan', 'Ġuse', 'Ġbasic', 'Ġarithmetic', 'Ġoperations', 'Ġ(+', ',', 'Ġ-,', 'Ġ*,', 'Ġ/', ')', 'Ġand', 'Ġeach', 'Ġnumber', 'Ġcan', 'Ġonly', 'Ġbe', 'Ġused', 'Ġonce', '.', 'ĠShow', 'Ġyour', 'Ġwork', 'Ġin', 'Ġ<', 'think', '>', 'Ġ</', 'think', '>', 'Ġtags', '.', 'ĠAnd', 'Ġreturn', 'Ġthe', 'Ġfinal', 'Ġanswer', 'Ġin', 'Ġ<', 'answer', '>', 'Ġ</', 'answer', '>', 'Ġtags', ',', 'Ġfor', 'Ġexample', 'Ġ<', 'answer', '>', 'Ġ(', '1', 'Ġ+', 'Ġ', '2', ')', 'Ġ/', 'Ġ', '3', 'Ġ</', 'answer', '>.', '<|im_end|>', 'Ċ', '<|im_start|>', 'assistant', 'Ċ', 'Let', 'Ġme', 'Ġsolve', 'Ġthis', 'Ġstep', 'Ġby', 'Ġstep', '.Ċ', '<th', 'ink', '>'], ['<|im_start|>', 'system', 'Ċ', 'You', 'Ġare', 'Ġa', 'Ġhelpful', 'Ġassistant', '.', 'ĠYou', 'Ġfirst', 'Ġthink', 'Ġabout', 'Ġthe', 'Ġreasoning', 'Ġprocess', 'Ġin', 'Ġyour', 'Ġmind', 'Ġand', 'Ġthen', 'Ġprovide', 'Ġthe', 'Ġuser', 'Ġwith', 'Ġthe', 'Ġanswer', '.', '<|im_end|>', 'Ċ', '<|im_start|>', 'user', 'Ċ', 'Using', 'Ġthe', 'Ġnumbers', 'Ġ[', '5', '9', 'Ġ', '3', '0', 'Ġ', '3', '5', 'Ġ', 'Ġ', '6', '],', 'Ġcreate', 'Ġan', 'Ġequation', 'Ġthat', 'Ġequals', 'Ġ', '4', '8', '.', 'ĠYou', 'Ġcan', 'Ġuse', 'Ġbasic', 'Ġarithmetic', 'Ġoperations', 'Ġ(+', ',', 'Ġ-,', 'Ġ*,', 'Ġ/', ')', 'Ġand', 'Ġeach', 'Ġnumber', 'Ġcan', 'Ġonly', 'Ġbe', 'Ġused', 'Ġonce', '.', 'ĠShow', 'Ġyour', 'Ġwork', 'Ġin', 'Ġ<', 'think', '>', 'Ġ</', 'think', '>', 'Ġtags', '.', 'ĠAnd', 'Ġreturn', 'Ġthe', 'Ġfinal', 'Ġanswer', 'Ġin', 'Ġ<', 'answer', '>', 'Ġ</', 'answer', '>', 'Ġtags', ',', 'Ġfor', 'Ġexample', 'Ġ<', 'answer', '>', 'Ġ(', '1', 'Ġ+', 'Ġ', '2', ')', 'Ġ/', 'Ġ', '3', 'Ġ</', 'answer', '>.', '<|im_end|>', 'Ċ', '<|im_start|>', 'assistant', 'Ċ', 'Let', 'Ġme', 'Ġsolve', 'Ġthis', 'Ġstep', 'Ġby', 'Ġstep', '.Ċ', '<th', 'ink', '>'], ['<|im_start|>', 'system', 'Ċ', 'You', 'Ġare', 'Ġa', 'Ġhelpful', 'Ġassistant', '.', 'ĠYou', 'Ġfirst', 'Ġthink', 'Ġabout', 'Ġthe', 'Ġreasoning', 'Ġprocess', 'Ġin', 'Ġyour', 'Ġmind', 'Ġand', 'Ġthen', 'Ġprovide', 'Ġthe', 'Ġuser', 'Ġwith', 'Ġthe', 'Ġanswer', '.', '<|im_end|>', 'Ċ', '<|im_start|>', 'user', 'Ċ', 'Using', 'Ġthe', 'Ġnumbers', 'Ġ[', '7', '4', 'Ġ', '7', '3', 'Ġ', '9', '0', 'Ġ', '8', '8', '],', 'Ġcreate', 'Ġan', 'Ġequation', 'Ġthat', 'Ġequals', 'Ġ', '8', '0', '.', 'ĠYou', 'Ġcan', 'Ġuse', 'Ġbasic', 'Ġarithmetic', 'Ġoperations', 'Ġ(+', ',', 'Ġ-,', 'Ġ*,', 'Ġ/', ')', 'Ġand', 'Ġeach', 'Ġnumber', 'Ġcan', 'Ġonly', 'Ġbe', 'Ġused', 'Ġonce', '.', 'ĠShow', 'Ġyour', 'Ġwork', 'Ġin', 'Ġ<', 'think', '>', 'Ġ</', 'think', '>', 'Ġtags', '.', 'ĠAnd', 'Ġreturn', 'Ġthe', 'Ġfinal', 'Ġanswer', 'Ġin', 'Ġ<', 'answer', '>', 'Ġ</', 'answer', '>', 'Ġtags', ',', 'Ġfor', 'Ġexample', 'Ġ<', 'answer', '>', 'Ġ(', '1', 'Ġ+', 'Ġ', '2', ')', 'Ġ/', 'Ġ', '3', 'Ġ</', 'answer', '>.', '<|im_end|>', 'Ċ', '<|im_start|>', 'assistant', 'Ċ', 'Let', 'Ġme', 'Ġsolve', 'Ġthis', 'Ġstep', 'Ġby', 'Ġstep', '.Ċ', '<th', 'ink', '>'], ['<|im_start|>', 'system', 'Ċ', 'You', 'Ġare', 'Ġa', 'Ġhelpful', 'Ġassistant', '.', 'ĠYou', 'Ġfirst', 'Ġthink', 'Ġabout', 'Ġthe', 'Ġreasoning', 'Ġprocess', 'Ġin', 'Ġyour', 'Ġmind', 'Ġand', 'Ġthen', 'Ġprovide', 'Ġthe', 'Ġuser', 'Ġwith', 'Ġthe', 'Ġanswer', '.', '<|im_end|>', 'Ċ', '<|im_start|>', 'user', 'Ċ', 'Using', 'Ġthe', 'Ġnumbers', 'Ġ[', '7', '4', 'Ġ', '8', '4', 'Ġ', '3', '7', '],', 'Ġcreate', 'Ġan', 'Ġequation', 'Ġthat', 'Ġequals', 'Ġ', '8', '6', '.', 'ĠYou', 'Ġcan', 'Ġuse', 'Ġbasic', 'Ġarithmetic', 'Ġoperations', 'Ġ(+', ',', 'Ġ-,', 'Ġ*,', 'Ġ/', ')', 'Ġand', 'Ġeach', 'Ġnumber', 'Ġcan', 'Ġonly', 'Ġbe', 'Ġused', 'Ġonce', '.', 'ĠShow', 'Ġyour', 'Ġwork', 'Ġin', 'Ġ<', 'think', '>', 'Ġ</', 'think', '>', 'Ġtags', '.', 'ĠAnd', 'Ġreturn', 'Ġthe', 'Ġfinal', 'Ġanswer', 'Ġin', 'Ġ<', 'answer', '>', 'Ġ</', 'answer', '>', 'Ġtags', ',', 'Ġfor', 'Ġexample', 'Ġ<', 'answer', '>', 'Ġ(', '1', 'Ġ+', 'Ġ', '2', ')', 'Ġ/', 'Ġ', '3', 'Ġ</', 'answer', '>.', '<|im_end|>', 'Ċ', '<|im_start|>', 'assistant', 'Ċ', 'Let', 'Ġme', 'Ġsolve', 'Ġthis', 'Ġstep', 'Ġby', 'Ġstep', '.Ċ', '<th', 'ink', '>'], ['<|im_start|>', 'system', 'Ċ', 'You', 'Ġare', 'Ġa', 'Ġhelpful', 'Ġassistant', '.', 'ĠYou', 'Ġfirst', 'Ġthink', 'Ġabout', 'Ġthe', 'Ġreasoning', 'Ġprocess', 'Ġin', 'Ġyour', 'Ġmind', 'Ġand', 'Ġthen', 'Ġprovide', 'Ġthe', 'Ġuser', 'Ġwith', 'Ġthe', 'Ġanswer', '.', '<|im_end|>', 'Ċ', '<|im_start|>', 'user', 'Ċ', 'Using', 'Ġthe', 'Ġnumbers', 'Ġ[', 'Ġ', '9', 'Ġ', '7', '5', 'Ġ', '1', '8', 'Ġ', 'Ġ', '8', '],', 'Ġcreate', 'Ġan', 'Ġequation', 'Ġthat', 'Ġequals', 'Ġ', '7', '8', '.', 'ĠYou', 'Ġcan', 'Ġuse', 'Ġbasic', 'Ġarithmetic', 'Ġoperations', 'Ġ(+', ',', 'Ġ-,', 'Ġ*,', 'Ġ/', ')', 'Ġand', 'Ġeach', 'Ġnumber', 'Ġcan', 'Ġonly', 'Ġbe', 'Ġused', 'Ġonce', '.', 'ĠShow', 'Ġyour', 'Ġwork', 'Ġin', 'Ġ<', 'think', '>', 'Ġ</', 'think', '>', 'Ġtags', '.', 'ĠAnd', 'Ġreturn', 'Ġthe', 'Ġfinal', 'Ġanswer', 'Ġin', 'Ġ<', 'answer', '>', 'Ġ</', 'answer', '>', 'Ġtags', ',', 'Ġfor', 'Ġexample', 'Ġ<', 'answer', '>', 'Ġ(', '1', 'Ġ+', 'Ġ', '2', ')', 'Ġ/', 'Ġ', '3', 'Ġ</', 'answer', '>.', '<|im_end|>', 'Ċ', '<|im_start|>', 'assistant', 'Ċ', 'Let', 'Ġme', 'Ġsolve', 'Ġthis', 'Ġstep', 'Ġby', 'Ġstep', '.Ċ', '<th', 'ink', '>'], ['<|im_start|>', 'system', 'Ċ', 'You', 'Ġare', 'Ġa', 'Ġhelpful', 'Ġassistant', '.', 'ĠYou', 'Ġfirst', 'Ġthink', 'Ġabout', 'Ġthe', 'Ġreasoning', 'Ġprocess', 'Ġin', 'Ġyour', 'Ġmind', 'Ġand', 'Ġthen', 'Ġprovide', 'Ġthe', 'Ġuser', 'Ġwith', 'Ġthe', 'Ġanswer', '.', '<|im_end|>', 'Ċ', '<|im_start|>', 'user', 'Ċ', 'Using', 'Ġthe', 'Ġnumbers', 'Ġ[', 'Ġ', '9', 'Ġ', '8', '2', 'Ġ', '8', '9', 'Ġ', '7', '3', '],', 'Ġcreate', 'Ġan', 'Ġequation', 'Ġthat', 'Ġequals', 'Ġ', '5', '4', '.', 'ĠYou', 'Ġcan', 'Ġuse', 'Ġbasic', 'Ġarithmetic', 'Ġoperations', 'Ġ(+', ',', 'Ġ-,', 'Ġ*,', 'Ġ/', ')', 'Ġand', 'Ġeach', 'Ġnumber', 'Ġcan', 'Ġonly', 'Ġbe', 'Ġused', 'Ġonce', '.', 'ĠShow', 'Ġyour', 'Ġwork', 'Ġin', 'Ġ<', 'think', '>', 'Ġ</', 'think', '>', 'Ġtags', '.', 'ĠAnd', 'Ġreturn', 'Ġthe', 'Ġfinal', 'Ġanswer', 'Ġin', 'Ġ<', 'answer', '>', 'Ġ</', 'answer', '>', 'Ġtags', ',', 'Ġfor', 'Ġexample', 'Ġ<', 'answer', '>', 'Ġ(', '1', 'Ġ+', 'Ġ', '2', ')', 'Ġ/', 'Ġ', '3', 'Ġ</', 'answer', '>.', '<|im_end|>', 'Ċ', '<|im_start|>', 'assistant', 'Ċ', 'Let', 'Ġme', 'Ġsolve', 'Ġthis', 'Ġstep', 'Ġby', 'Ġstep', '.Ċ', '<th', 'ink', '>'], ['<|im_start|>', 'system', 'Ċ', 'You', 'Ġare', 'Ġa', 'Ġhelpful', 'Ġassistant', '.', 'ĠYou', 'Ġfirst', 'Ġthink', 'Ġabout', 'Ġthe', 'Ġreasoning', 'Ġprocess', 'Ġin', 'Ġyour', 'Ġmind', 'Ġand', 'Ġthen', 'Ġprovide', 'Ġthe', 'Ġuser', 'Ġwith', 'Ġthe', 'Ġanswer', '.', '<|im_end|>', 'Ċ', '<|im_start|>', 'user', 'Ċ', 'Using', 'Ġthe', 'Ġnumbers', 'Ġ[', '7', '6', 'Ġ', '3', '2', 'Ġ', '2', '6', 'Ġ', '3', '2', '],', 'Ġcreate', 'Ġan', 'Ġequation', 'Ġthat', 'Ġequals', 'Ġ', '4', '9', '.', 'ĠYou', 'Ġcan', 'Ġuse', 'Ġbasic', 'Ġarithmetic', 'Ġoperations', 'Ġ(+', ',', 'Ġ-,', 'Ġ*,', 'Ġ/', ')', 'Ġand', 'Ġeach', 'Ġnumber', 'Ġcan', 'Ġonly', 'Ġbe', 'Ġused', 'Ġonce', '.', 'ĠShow', 'Ġyour', 'Ġwork', 'Ġin', 'Ġ<', 'think', '>', 'Ġ</', 'think', '>', 'Ġtags', '.', 'ĠAnd', 'Ġreturn', 'Ġthe', 'Ġfinal', 'Ġanswer', 'Ġin', 'Ġ<', 'answer', '>', 'Ġ</', 'answer', '>', 'Ġtags', ',', 'Ġfor', 'Ġexample', 'Ġ<', 'answer', '>', 'Ġ(', '1', 'Ġ+', 'Ġ', '2', ')', 'Ġ/', 'Ġ', '3', 'Ġ</', 'answer', '>.', '<|im_end|>', 'Ċ', '<|im_start|>', 'assistant', 'Ċ', 'Let', 'Ġme', 'Ġsolve', 'Ġthis', 'Ġstep', 'Ġby', 'Ġstep', '.Ċ', '<th', 'ink', '>'], ['<|im_start|>', 'system', 'Ċ', 'You', 'Ġare', 'Ġa', 'Ġhelpful', 'Ġassistant', '.', 'ĠYou', 'Ġfirst', 'Ġthink', 'Ġabout', 'Ġthe', 'Ġreasoning', 'Ġprocess', 'Ġin', 'Ġyour', 'Ġmind', 'Ġand', 'Ġthen', 'Ġprovide', 'Ġthe', 'Ġuser', 'Ġwith', 'Ġthe', 'Ġanswer', '.', '<|im_end|>', 'Ċ', '<|im_start|>', 'user', 'Ċ', 'Using', 'Ġthe', 'Ġnumbers', 'Ġ[', '7', '6', 'Ġ', '1', '0', 'Ġ', '8', '2', 'Ġ', 'Ġ', '4', '],', 'Ġcreate', 'Ġan', 'Ġequation', 'Ġthat', 'Ġequals', 'Ġ', '1', '0', '0', '.', 'ĠYou', 'Ġcan', 'Ġuse', 'Ġbasic', 'Ġarithmetic', 'Ġoperations', 'Ġ(+', ',', 'Ġ-,', 'Ġ*,', 'Ġ/', ')', 'Ġand', 'Ġeach', 'Ġnumber', 'Ġcan', 'Ġonly', 'Ġbe', 'Ġused', 'Ġonce', '.', 'ĠShow', 'Ġyour', 'Ġwork', 'Ġin', 'Ġ<', 'think', '>', 'Ġ</', 'think', '>', 'Ġtags', '.', 'ĠAnd', 'Ġreturn', 'Ġthe', 'Ġfinal', 'Ġanswer', 'Ġin', 'Ġ<', 'answer', '>', 'Ġ</', 'answer', '>', 'Ġtags', ',', 'Ġfor', 'Ġexample', 'Ġ<', 'answer', '>', 'Ġ(', '1', 'Ġ+', 'Ġ', '2', ')', 'Ġ/', 'Ġ', '3', 'Ġ</', 'answer', '>.', '<|im_end|>', 'Ċ', '<|im_start|>', 'assistant', 'Ċ', 'Let', 'Ġme', 'Ġsolve', 'Ġthis', 'Ġstep', 'Ġby', 'Ġstep', '.Ċ', '<th', 'ink', '>'], ['<|im_start|>', 'system', 'Ċ', 'You', 'Ġare', 'Ġa', 'Ġhelpful', 'Ġassistant', '.', 'ĠYou', 'Ġfirst', 'Ġthink', 'Ġabout', 'Ġthe', 'Ġreasoning', 'Ġprocess', 'Ġin', 'Ġyour', 'Ġmind', 'Ġand', 'Ġthen', 'Ġprovide', 'Ġthe', 'Ġuser', 'Ġwith', 'Ġthe', 'Ġanswer', '.', '<|im_end|>', 'Ċ', '<|im_start|>', 'user', 'Ċ', 'Using', 'Ġthe', 'Ġnumbers', 'Ġ[', '9', '0', 'Ġ', '8', '5', 'Ġ', '5', '7', 'Ġ', '4', '9', '],', 'Ġcreate', 'Ġan', 'Ġequation', 'Ġthat', 'Ġequals', 'Ġ', '1', '3', '.', 'ĠYou', 'Ġcan', 'Ġuse', 'Ġbasic', 'Ġarithmetic', 'Ġoperations', 'Ġ(+', ',', 'Ġ-,', 'Ġ*,', 'Ġ/', ')', 'Ġand', 'Ġeach', 'Ġnumber', 'Ġcan', 'Ġonly', 'Ġbe', 'Ġused', 'Ġonce', '.', 'ĠShow', 'Ġyour', 'Ġwork', 'Ġin', 'Ġ<', 'think', '>', 'Ġ</', 'think', '>', 'Ġtags', '.', 'ĠAnd', 'Ġreturn', 'Ġthe', 'Ġfinal', 'Ġanswer', 'Ġin', 'Ġ<', 'answer', '>', 'Ġ</', 'answer', '>', 'Ġtags', ',', 'Ġfor', 'Ġexample', 'Ġ<', 'answer', '>', 'Ġ(', '1', 'Ġ+', 'Ġ', '2', ')', 'Ġ/', 'Ġ', '3', 'Ġ</', 'answer', '>.', '<|im_end|>', 'Ċ', '<|im_start|>', 'assistant', 'Ċ', 'Let', 'Ġme', 'Ġsolve', 'Ġthis', 'Ġstep', 'Ġby', 'Ġstep', '.Ċ', '<th', 'ink', '>']], prefix_token_ids=[[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 1446, 1156, 1744, 911, 279, 32711, 1882, 304, 697, 3971, 323, 1221, 3410, 279, 1196, 448, 279, 4226, 13, 151645, 198, 151644, 872, 198, 16429, 279, 5109, 508, 16, 23, 220, 21, 24, 220, 22, 19, 220, 18, 19, 1125, 1855, 458, 23606, 429, 16819, 220, 24, 16, 13, 1446, 646, 990, 6770, 34784, 7525, 17973, 11, 85922, 11777, 608, 8, 323, 1817, 1372, 646, 1172, 387, 1483, 3055, 13, 6928, 697, 975, 304, 366, 26865, 29, 690, 26865, 29, 9492, 13, 1597, 470, 279, 1590, 4226, 304, 366, 9217, 29, 690, 9217, 29, 9492, 11, 369, 3110, 366, 9217, 29, 320, 16, 488, 220, 17, 8, 608, 220, 18, 690, 9217, 14276, 151645, 198, 151644, 77091, 198, 10061, 752, 11625, 419, 3019, 553, 3019, 624, 13708, 766, 29], [151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 1446, 1156, 1744, 911, 279, 32711, 1882, 304, 697, 3971, 323, 1221, 3410, 279, 1196, 448, 279, 4226, 13, 151645, 198, 151644, 872, 198, 16429, 279, 5109, 508, 220, 19, 220, 19, 22, 220, 16, 16, 1125, 1855, 458, 23606, 429, 16819, 220, 24, 16, 13, 1446, 646, 990, 6770, 34784, 7525, 17973, 11, 85922, 11777, 608, 8, 323, 1817, 1372, 646, 1172, 387, 1483, 3055, 13, 6928, 697, 975, 304, 366, 26865, 29, 690, 26865, 29, 9492, 13, 1597, 470, 279, 1590, 4226, 304, 366, 9217, 29, 690, 9217, 29, 9492, 11, 369, 3110, 366, 9217, 29, 320, 16, 488, 220, 17, 8, 608, 220, 18, 690, 9217, 14276, 151645, 198, 151644, 77091, 198, 10061, 752, 11625, 419, 3019, 553, 3019, 624, 13708, 766, 29], [151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 1446, 1156, 1744, 911, 279, 32711, 1882, 304, 697, 3971, 323, 1221, 3410, 279, 1196, 448, 279, 4226, 13, 151645, 198, 151644, 872, 198, 16429, 279, 5109, 508, 23, 18, 220, 20, 20, 220, 18, 18, 220, 23, 20, 1125, 1855, 458, 23606, 429, 16819, 220, 23, 21, 13, 1446, 646, 990, 6770, 34784, 7525, 17973, 11, 85922, 11777, 608, 8, 323, 1817, 1372, 646, 1172, 387, 1483, 3055, 13, 6928, 697, 975, 304, 366, 26865, 29, 690, 26865, 29, 9492, 13, 1597, 470, 279, 1590, 4226, 304, 366, 9217, 29, 690, 9217, 29, 9492, 11, 369, 3110, 366, 9217, 29, 320, 16, 488, 220, 17, 8, 608, 220, 18, 690, 9217, 14276, 151645, 198, 151644, 77091, 198, 10061, 752, 11625, 419, 3019, 553, 3019, 624, 13708, 766, 29], [151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 1446, 1156, 1744, 911, 279, 32711, 1882, 304, 697, 3971, 323, 1221, 3410, 279, 1196, 448, 279, 4226, 13, 151645, 198, 151644, 872, 198, 16429, 279, 5109, 508, 23, 15, 220, 20, 17, 220, 24, 18, 220, 220, 22, 1125, 1855, 458, 23606, 429, 16819, 220, 21, 20, 13, 1446, 646, 990, 6770, 34784, 7525, 17973, 11, 85922, 11777, 608, 8, 323, 1817, 1372, 646, 1172, 387, 1483, 3055, 13, 6928, 697, 975, 304, 366, 26865, 29, 690, 26865, 29, 9492, 13, 1597, 470, 279, 1590, 4226, 304, 366, 9217, 29, 690, 9217, 29, 9492, 11, 369, 3110, 366, 9217, 29, 320, 16, 488, 220, 17, 8, 608, 220, 18, 690, 9217, 14276, 151645, 198, 151644, 77091, 198, 10061, 752, 11625, 419, 3019, 553, 3019, 624, 13708, 766, 29], [151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 1446, 1156, 1744, 911, 279, 32711, 1882, 304, 697, 3971, 323, 1221, 3410, 279, 1196, 448, 279, 4226, 13, 151645, 198, 151644, 872, 198, 16429, 279, 5109, 508, 22, 17, 220, 21, 22, 220, 19, 16, 1125, 1855, 458, 23606, 429, 16819, 220, 24, 23, 13, 1446, 646, 990, 6770, 34784, 7525, 17973, 11, 85922, 11777, 608, 8, 323, 1817, 1372, 646, 1172, 387, 1483, 3055, 13, 6928, 697, 975, 304, 366, 26865, 29, 690, 26865, 29, 9492, 13, 1597, 470, 279, 1590, 4226, 304, 366, 9217, 29, 690, 9217, 29, 9492, 11, 369, 3110, 366, 9217, 29, 320, 16, 488, 220, 17, 8, 608, 220, 18, 690, 9217, 14276, 151645, 198, 151644, 77091, 198, 10061, 752, 11625, 419, 3019, 553, 3019, 624, 13708, 766, 29], [151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 1446, 1156, 1744, 911, 279, 32711, 1882, 304, 697, 3971, 323, 1221, 3410, 279, 1196, 448, 279, 4226, 13, 151645, 198, 151644, 872, 198, 16429, 279, 5109, 508, 16, 15, 220, 220, 20, 220, 24, 23, 1125, 1855, 458, 23606, 429, 16819, 220, 19, 24, 13, 1446, 646, 990, 6770, 34784, 7525, 17973, 11, 85922, 11777, 608, 8, 323, 1817, 1372, 646, 1172, 387, 1483, 3055, 13, 6928, 697, 975, 304, 366, 26865, 29, 690, 26865, 29, 9492, 13, 1597, 470, 279, 1590, 4226, 304, 366, 9217, 29, 690, 9217, 29, 9492, 11, 369, 3110, 366, 9217, 29, 320, 16, 488, 220, 17, 8, 608, 220, 18, 690, 9217, 14276, 151645, 198, 151644, 77091, 198, 10061, 752, 11625, 419, 3019, 553, 3019, 624, 13708, 766, 29], [151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 1446, 1156, 1744, 911, 279, 32711, 1882, 304, 697, 3971, 323, 1221, 3410, 279, 1196, 448, 279, 4226, 13, 151645, 198, 151644, 872, 198, 16429, 279, 5109, 508, 20, 20, 220, 24, 23, 220, 220, 22, 1125, 1855, 458, 23606, 429, 16819, 220, 20, 15, 13, 1446, 646, 990, 6770, 34784, 7525, 17973, 11, 85922, 11777, 608, 8, 323, 1817, 1372, 646, 1172, 387, 1483, 3055, 13, 6928, 697, 975, 304, 366, 26865, 29, 690, 26865, 29, 9492, 13, 1597, 470, 279, 1590, 4226, 304, 366, 9217, 29, 690, 9217, 29, 9492, 11, 369, 3110, 366, 9217, 29, 320, 16, 488, 220, 17, 8, 608, 220, 18, 690, 9217, 14276, 151645, 198, 151644, 77091, 198, 10061, 752, 11625, 419, 3019, 553, 3019, 624, 13708, 766, 29], [151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 1446, 1156, 1744, 911, 279, 32711, 1882, 304, 697, 3971, 323, 1221, 3410, 279, 1196, 448, 279, 4226, 13, 151645, 198, 151644, 872, 198, 16429, 279, 5109, 508, 16, 24, 220, 20, 15, 220, 21, 15, 1125, 1855, 458, 23606, 429, 16819, 220, 17, 24, 13, 1446, 646, 990, 6770, 34784, 7525, 17973, 11, 85922, 11777, 608, 8, 323, 1817, 1372, 646, 1172, 387, 1483, 3055, 13, 6928, 697, 975, 304, 366, 26865, 29, 690, 26865, 29, 9492, 13, 1597, 470, 279, 1590, 4226, 304, 366, 9217, 29, 690, 9217, 29, 9492, 11, 369, 3110, 366, 9217, 29, 320, 16, 488, 220, 17, 8, 608, 220, 18, 690, 9217, 14276, 151645, 198, 151644, 77091, 198, 10061, 752, 11625, 419, 3019, 553, 3019, 624, 13708, 766, 29], [151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 1446, 1156, 1744, 911, 279, 32711, 1882, 304, 697, 3971, 323, 1221, 3410, 279, 1196, 448, 279, 4226, 13, 151645, 198, 151644, 872, 198, 16429, 279, 5109, 508, 16, 17, 220, 23, 19, 220, 19, 17, 220, 17, 15, 1125, 1855, 458, 23606, 429, 16819, 220, 20, 15, 13, 1446, 646, 990, 6770, 34784, 7525, 17973, 11, 85922, 11777, 608, 8, 323, 1817, 1372, 646, 1172, 387, 1483, 3055, 13, 6928, 697, 975, 304, 366, 26865, 29, 690, 26865, 29, 9492, 13, 1597, 470, 279, 1590, 4226, 304, 366, 9217, 29, 690, 9217, 29, 9492, 11, 369, 3110, 366, 9217, 29, 320, 16, 488, 220, 17, 8, 608, 220, 18, 690, 9217, 14276, 151645, 198, 151644, 77091, 198, 10061, 752, 11625, 419, 3019, 553, 3019, 624, 13708, 766, 29], [151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 1446, 1156, 1744, 911, 279, 32711, 1882, 304, 697, 3971, 323, 1221, 3410, 279, 1196, 448, 279, 4226, 13, 151645, 198, 151644, 872, 198, 16429, 279, 5109, 508, 19, 19, 220, 18, 15, 220, 18, 24, 220, 220, 18, 1125, 1855, 458, 23606, 429, 16819, 220, 21, 22, 13, 1446, 646, 990, 6770, 34784, 7525, 17973, 11, 85922, 11777, 608, 8, 323, 1817, 1372, 646, 1172, 387, 1483, 3055, 13, 6928, 697, 975, 304, 366, 26865, 29, 690, 26865, 29, 9492, 13, 1597, 470, 279, 1590, 4226, 304, 366, 9217, 29, 690, 9217, 29, 9492, 11, 369, 3110, 366, 9217, 29, 320, 16, 488, 220, 17, 8, 608, 220, 18, 690, 9217, 14276, 151645, 198, 151644, 77091, 198, 10061, 752, 11625, 419, 3019, 553, 3019, 624, 13708, 766, 29], [151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 1446, 1156, 1744, 911, 279, 32711, 1882, 304, 697, 3971, 323, 1221, 3410, 279, 1196, 448, 279, 4226, 13, 151645, 198, 151644, 872, 198, 16429, 279, 5109, 508, 19, 21, 220, 20, 20, 220, 18, 20, 1125, 1855, 458, 23606, 429, 16819, 220, 17, 21, 13, 1446, 646, 990, 6770, 34784, 7525, 17973, 11, 85922, 11777, 608, 8, 323, 1817, 1372, 646, 1172, 387, 1483, 3055, 13, 6928, 697, 975, 304, 366, 26865, 29, 690, 26865, 29, 9492, 13, 1597, 470, 279, 1590, 4226, 304, 366, 9217, 29, 690, 9217, 29, 9492, 11, 369, 3110, 366, 9217, 29, 320, 16, 488, 220, 17, 8, 608, 220, 18, 690, 9217, 14276, 151645, 198, 151644, 77091, 198, 10061, 752, 11625, 419, 3019, 553, 3019, 624, 13708, 766, 29], [151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 1446, 1156, 1744, 911, 279, 32711, 1882, 304, 697, 3971, 323, 1221, 3410, 279, 1196, 448, 279, 4226, 13, 151645, 198, 151644, 872, 198, 16429, 279, 5109, 508, 21, 24, 220, 17, 15, 220, 21, 23, 220, 18, 21, 1125, 1855, 458, 23606, 429, 16819, 220, 24, 17, 13, 1446, 646, 990, 6770, 34784, 7525, 17973, 11, 85922, 11777, 608, 8, 323, 1817, 1372, 646, 1172, 387, 1483, 3055, 13, 6928, 697, 975, 304, 366, 26865, 29, 690, 26865, 29, 9492, 13, 1597, 470, 279, 1590, 4226, 304, 366, 9217, 29, 690, 9217, 29, 9492, 11, 369, 3110, 366, 9217, 29, 320, 16, 488, 220, 17, 8, 608, 220, 18, 690, 9217, 14276, 151645, 198, 151644, 77091, 198, 10061, 752, 11625, 419, 3019, 553, 3019, 624, 13708, 766, 29], [151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 1446, 1156, 1744, 911, 279, 32711, 1882, 304, 697, 3971, 323, 1221, 3410, 279, 1196, 448, 279, 4226, 13, 151645, 198, 151644, 872, 198, 16429, 279, 5109, 508, 21, 17, 220, 23, 24, 220, 220, 18, 220, 21, 16, 1125, 1855, 458, 23606, 429, 16819, 220, 18, 22, 13, 1446, 646, 990, 6770, 34784, 7525, 17973, 11, 85922, 11777, 608, 8, 323, 1817, 1372, 646, 1172, 387, 1483, 3055, 13, 6928, 697, 975, 304, 366, 26865, 29, 690, 26865, 29, 9492, 13, 1597, 470, 279, 1590, 4226, 304, 366, 9217, 29, 690, 9217, 29, 9492, 11, 369, 3110, 366, 9217, 29, 320, 16, 488, 220, 17, 8, 608, 220, 18, 690, 9217, 14276, 151645, 198, 151644, 77091, 198, 10061, 752, 11625, 419, 3019, 553, 3019, 624, 13708, 766, 29], [151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 1446, 1156, 1744, 911, 279, 32711, 1882, 304, 697, 3971, 323, 1221, 3410, 279, 1196, 448, 279, 4226, 13, 151645, 198, 151644, 872, 198, 16429, 279, 5109, 508, 17, 16, 220, 16, 15, 220, 220, 21, 220, 18, 21, 1125, 1855, 458, 23606, 429, 16819, 220, 17, 15, 13, 1446, 646, 990, 6770, 34784, 7525, 17973, 11, 85922, 11777, 608, 8, 323, 1817, 1372, 646, 1172, 387, 1483, 3055, 13, 6928, 697, 975, 304, 366, 26865, 29, 690, 26865, 29, 9492, 13, 1597, 470, 279, 1590, 4226, 304, 366, 9217, 29, 690, 9217, 29, 9492, 11, 369, 3110, 366, 9217, 29, 320, 16, 488, 220, 17, 8, 608, 220, 18, 690, 9217, 14276, 151645, 198, 151644, 77091, 198, 10061, 752, 11625, 419, 3019, 553, 3019, 624, 13708, 766, 29], [151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 1446, 1156, 1744, 911, 279, 32711, 1882, 304, 697, 3971, 323, 1221, 3410, 279, 1196, 448, 279, 4226, 13, 151645, 198, 151644, 872, 198, 16429, 279, 5109, 508, 24, 24, 220, 22, 20, 220, 21, 21, 220, 220, 20, 1125, 1855, 458, 23606, 429, 16819, 220, 16, 21, 13, 1446, 646, 990, 6770, 34784, 7525, 17973, 11, 85922, 11777, 608, 8, 323, 1817, 1372, 646, 1172, 387, 1483, 3055, 13, 6928, 697, 975, 304, 366, 26865, 29, 690, 26865, 29, 9492, 13, 1597, 470, 279, 1590, 4226, 304, 366, 9217, 29, 690, 9217, 29, 9492, 11, 369, 3110, 366, 9217, 29, 320, 16, 488, 220, 17, 8, 608, 220, 18, 690, 9217, 14276, 151645, 198, 151644, 77091, 198, 10061, 752, 11625, 419, 3019, 553, 3019, 624, 13708, 766, 29], [151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 1446, 1156, 1744, 911, 279, 32711, 1882, 304, 697, 3971, 323, 1221, 3410, 279, 1196, 448, 279, 4226, 13, 151645, 198, 151644, 872, 198, 16429, 279, 5109, 508, 16, 16, 220, 23, 19, 220, 21, 20, 1125, 1855, 458, 23606, 429, 16819, 220, 18, 15, 13, 1446, 646, 990, 6770, 34784, 7525, 17973, 11, 85922, 11777, 608, 8, 323, 1817, 1372, 646, 1172, 387, 1483, 3055, 13, 6928, 697, 975, 304, 366, 26865, 29, 690, 26865, 29, 9492, 13, 1597, 470, 279, 1590, 4226, 304, 366, 9217, 29, 690, 9217, 29, 9492, 11, 369, 3110, 366, 9217, 29, 320, 16, 488, 220, 17, 8, 608, 220, 18, 690, 9217, 14276, 151645, 198, 151644, 77091, 198, 10061, 752, 11625, 419, 3019, 553, 3019, 624, 13708, 766, 29], [151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 1446, 1156, 1744, 911, 279, 32711, 1882, 304, 697, 3971, 323, 1221, 3410, 279, 1196, 448, 279, 4226, 13, 151645, 198, 151644, 872, 198, 16429, 279, 5109, 508, 17, 23, 220, 20, 24, 220, 18, 20, 1125, 1855, 458, 23606, 429, 16819, 220, 20, 17, 13, 1446, 646, 990, 6770, 34784, 7525, 17973, 11, 85922, 11777, 608, 8, 323, 1817, 1372, 646, 1172, 387, 1483, 3055, 13, 6928, 697, 975, 304, 366, 26865, 29, 690, 26865, 29, 9492, 13, 1597, 470, 279, 1590, 4226, 304, 366, 9217, 29, 690, 9217, 29, 9492, 11, 369, 3110, 366, 9217, 29, 320, 16, 488, 220, 17, 8, 608, 220, 18, 690, 9217, 14276, 151645, 198, 151644, 77091, 198, 10061, 752, 11625, 419, 3019, 553, 3019, 624, 13708, 766, 29], [151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 1446, 1156, 1744, 911, 279, 32711, 1882, 304, 697, 3971, 323, 1221, 3410, 279, 1196, 448, 279, 4226, 13, 151645, 198, 151644, 872, 198, 16429, 279, 5109, 508, 21, 15, 220, 19, 22, 220, 220, 19, 220, 16, 17, 1125, 1855, 458, 23606, 429, 16819, 220, 20, 24, 13, 1446, 646, 990, 6770, 34784, 7525, 17973, 11, 85922, 11777, 608, 8, 323, 1817, 1372, 646, 1172, 387, 1483, 3055, 13, 6928, 697, 975, 304, 366, 26865, 29, 690, 26865, 29, 9492, 13, 1597, 470, 279, 1590, 4226, 304, 366, 9217, 29, 690, 9217, 29, 9492, 11, 369, 3110, 366, 9217, 29, 320, 16, 488, 220, 17, 8, 608, 220, 18, 690, 9217, 14276, 151645, 198, 151644, 77091, 198, 10061, 752, 11625, 419, 3019, 553, 3019, 624, 13708, 766, 29], [151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 1446, 1156, 1744, 911, 279, 32711, 1882, 304, 697, 3971, 323, 1221, 3410, 279, 1196, 448, 279, 4226, 13, 151645, 198, 151644, 872, 198, 16429, 279, 5109, 508, 17, 16, 220, 24, 15, 220, 22, 20, 220, 18, 17, 1125, 1855, 458, 23606, 429, 16819, 220, 24, 18, 13, 1446, 646, 990, 6770, 34784, 7525, 17973, 11, 85922, 11777, 608, 8, 323, 1817, 1372, 646, 1172, 387, 1483, 3055, 13, 6928, 697, 975, 304, 366, 26865, 29, 690, 26865, 29, 9492, 13, 1597, 470, 279, 1590, 4226, 304, 366, 9217, 29, 690, 9217, 29, 9492, 11, 369, 3110, 366, 9217, 29, 320, 16, 488, 220, 17, 8, 608, 220, 18, 690, 9217, 14276, 151645, 198, 151644, 77091, 198, 10061, 752, 11625, 419, 3019, 553, 3019, 624, 13708, 766, 29], [151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 1446, 1156, 1744, 911, 279, 32711, 1882, 304, 697, 3971, 323, 1221, 3410, 279, 1196, 448, 279, 4226, 13, 151645, 198, 151644, 872, 198, 16429, 279, 5109, 508, 19, 23, 220, 21, 15, 220, 21, 19, 220, 24, 21, 1125, 1855, 458, 23606, 429, 16819, 220, 22, 23, 13, 1446, 646, 990, 6770, 34784, 7525, 17973, 11, 85922, 11777, 608, 8, 323, 1817, 1372, 646, 1172, 387, 1483, 3055, 13, 6928, 697, 975, 304, 366, 26865, 29, 690, 26865, 29, 9492, 13, 1597, 470, 279, 1590, 4226, 304, 366, 9217, 29, 690, 9217, 29, 9492, 11, 369, 3110, 366, 9217, 29, 320, 16, 488, 220, 17, 8, 608, 220, 18, 690, 9217, 14276, 151645, 198, 151644, 77091, 198, 10061, 752, 11625, 419, 3019, 553, 3019, 624, 13708, 766, 29], [151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 1446, 1156, 1744, 911, 279, 32711, 1882, 304, 697, 3971, 323, 1221, 3410, 279, 1196, 448, 279, 4226, 13, 151645, 198, 151644, 872, 198, 16429, 279, 5109, 508, 220, 17, 220, 17, 15, 220, 18, 18, 1125, 1855, 458, 23606, 429, 16819, 220, 20, 16, 13, 1446, 646, 990, 6770, 34784, 7525, 17973, 11, 85922, 11777, 608, 8, 323, 1817, 1372, 646, 1172, 387, 1483, 3055, 13, 6928, 697, 975, 304, 366, 26865, 29, 690, 26865, 29, 9492, 13, 1597, 470, 279, 1590, 4226, 304, 366, 9217, 29, 690, 9217, 29, 9492, 11, 369, 3110, 366, 9217, 29, 320, 16, 488, 220, 17, 8, 608, 220, 18, 690, 9217, 14276, 151645, 198, 151644, 77091, 198, 10061, 752, 11625, 419, 3019, 553, 3019, 624, 13708, 766, 29], [151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 1446, 1156, 1744, 911, 279, 32711, 1882, 304, 697, 3971, 323, 1221, 3410, 279, 1196, 448, 279, 4226, 13, 151645, 198, 151644, 872, 198, 16429, 279, 5109, 508, 21, 23, 220, 18, 18, 220, 21, 20, 220, 16, 20, 1125, 1855, 458, 23606, 429, 16819, 220, 22, 20, 13, 1446, 646, 990, 6770, 34784, 7525, 17973, 11, 85922, 11777, 608, 8, 323, 1817, 1372, 646, 1172, 387, 1483, 3055, 13, 6928, 697, 975, 304, 366, 26865, 29, 690, 26865, 29, 9492, 13, 1597, 470, 279, 1590, 4226, 304, 366, 9217, 29, 690, 9217, 29, 9492, 11, 369, 3110, 366, 9217, 29, 320, 16, 488, 220, 17, 8, 608, 220, 18, 690, 9217, 14276, 151645, 198, 151644, 77091, 198, 10061, 752, 11625, 419, 3019, 553, 3019, 624, 13708, 766, 29], [151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 1446, 1156, 1744, 911, 279, 32711, 1882, 304, 697, 3971, 323, 1221, 3410, 279, 1196, 448, 279, 4226, 13, 151645, 198, 151644, 872, 198, 16429, 279, 5109, 508, 20, 22, 220, 21, 22, 220, 220, 22, 220, 16, 15, 1125, 1855, 458, 23606, 429, 16819, 220, 21, 18, 13, 1446, 646, 990, 6770, 34784, 7525, 17973, 11, 85922, 11777, 608, 8, 323, 1817, 1372, 646, 1172, 387, 1483, 3055, 13, 6928, 697, 975, 304, 366, 26865, 29, 690, 26865, 29, 9492, 13, 1597, 470, 279, 1590, 4226, 304, 366, 9217, 29, 690, 9217, 29, 9492, 11, 369, 3110, 366, 9217, 29, 320, 16, 488, 220, 17, 8, 608, 220, 18, 690, 9217, 14276, 151645, 198, 151644, 77091, 198, 10061, 752, 11625, 419, 3019, 553, 3019, 624, 13708, 766, 29], [151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 1446, 1156, 1744, 911, 279, 32711, 1882, 304, 697, 3971, 323, 1221, 3410, 279, 1196, 448, 279, 4226, 13, 151645, 198, 151644, 872, 198, 16429, 279, 5109, 508, 20, 17, 220, 16, 22, 220, 16, 24, 220, 17, 16, 1125, 1855, 458, 23606, 429, 16819, 220, 23, 21, 13, 1446, 646, 990, 6770, 34784, 7525, 17973, 11, 85922, 11777, 608, 8, 323, 1817, 1372, 646, 1172, 387, 1483, 3055, 13, 6928, 697, 975, 304, 366, 26865, 29, 690, 26865, 29, 9492, 13, 1597, 470, 279, 1590, 4226, 304, 366, 9217, 29, 690, 9217, 29, 9492, 11, 369, 3110, 366, 9217, 29, 320, 16, 488, 220, 17, 8, 608, 220, 18, 690, 9217, 14276, 151645, 198, 151644, 77091, 198, 10061, 752, 11625, 419, 3019, 553, 3019, 624, 13708, 766, 29], [151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 1446, 1156, 1744, 911, 279, 32711, 1882, 304, 697, 3971, 323, 1221, 3410, 279, 1196, 448, 279, 4226, 13, 151645, 198, 151644, 872, 198, 16429, 279, 5109, 508, 20, 24, 220, 18, 15, 220, 18, 20, 220, 220, 21, 1125, 1855, 458, 23606, 429, 16819, 220, 19, 23, 13, 1446, 646, 990, 6770, 34784, 7525, 17973, 11, 85922, 11777, 608, 8, 323, 1817, 1372, 646, 1172, 387, 1483, 3055, 13, 6928, 697, 975, 304, 366, 26865, 29, 690, 26865, 29, 9492, 13, 1597, 470, 279, 1590, 4226, 304, 366, 9217, 29, 690, 9217, 29, 9492, 11, 369, 3110, 366, 9217, 29, 320, 16, 488, 220, 17, 8, 608, 220, 18, 690, 9217, 14276, 151645, 198, 151644, 77091, 198, 10061, 752, 11625, 419, 3019, 553, 3019, 624, 13708, 766, 29], [151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 1446, 1156, 1744, 911, 279, 32711, 1882, 304, 697, 3971, 323, 1221, 3410, 279, 1196, 448, 279, 4226, 13, 151645, 198, 151644, 872, 198, 16429, 279, 5109, 508, 22, 19, 220, 22, 18, 220, 24, 15, 220, 23, 23, 1125, 1855, 458, 23606, 429, 16819, 220, 23, 15, 13, 1446, 646, 990, 6770, 34784, 7525, 17973, 11, 85922, 11777, 608, 8, 323, 1817, 1372, 646, 1172, 387, 1483, 3055, 13, 6928, 697, 975, 304, 366, 26865, 29, 690, 26865, 29, 9492, 13, 1597, 470, 279, 1590, 4226, 304, 366, 9217, 29, 690, 9217, 29, 9492, 11, 369, 3110, 366, 9217, 29, 320, 16, 488, 220, 17, 8, 608, 220, 18, 690, 9217, 14276, 151645, 198, 151644, 77091, 198, 10061, 752, 11625, 419, 3019, 553, 3019, 624, 13708, 766, 29], [151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 1446, 1156, 1744, 911, 279, 32711, 1882, 304, 697, 3971, 323, 1221, 3410, 279, 1196, 448, 279, 4226, 13, 151645, 198, 151644, 872, 198, 16429, 279, 5109, 508, 22, 19, 220, 23, 19, 220, 18, 22, 1125, 1855, 458, 23606, 429, 16819, 220, 23, 21, 13, 1446, 646, 990, 6770, 34784, 7525, 17973, 11, 85922, 11777, 608, 8, 323, 1817, 1372, 646, 1172, 387, 1483, 3055, 13, 6928, 697, 975, 304, 366, 26865, 29, 690, 26865, 29, 9492, 13, 1597, 470, 279, 1590, 4226, 304, 366, 9217, 29, 690, 9217, 29, 9492, 11, 369, 3110, 366, 9217, 29, 320, 16, 488, 220, 17, 8, 608, 220, 18, 690, 9217, 14276, 151645, 198, 151644, 77091, 198, 10061, 752, 11625, 419, 3019, 553, 3019, 624, 13708, 766, 29], [151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 1446, 1156, 1744, 911, 279, 32711, 1882, 304, 697, 3971, 323, 1221, 3410, 279, 1196, 448, 279, 4226, 13, 151645, 198, 151644, 872, 198, 16429, 279, 5109, 508, 220, 24, 220, 22, 20, 220, 16, 23, 220, 220, 23, 1125, 1855, 458, 23606, 429, 16819, 220, 22, 23, 13, 1446, 646, 990, 6770, 34784, 7525, 17973, 11, 85922, 11777, 608, 8, 323, 1817, 1372, 646, 1172, 387, 1483, 3055, 13, 6928, 697, 975, 304, 366, 26865, 29, 690, 26865, 29, 9492, 13, 1597, 470, 279, 1590, 4226, 304, 366, 9217, 29, 690, 9217, 29, 9492, 11, 369, 3110, 366, 9217, 29, 320, 16, 488, 220, 17, 8, 608, 220, 18, 690, 9217, 14276, 151645, 198, 151644, 77091, 198, 10061, 752, 11625, 419, 3019, 553, 3019, 624, 13708, 766, 29], [151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 1446, 1156, 1744, 911, 279, 32711, 1882, 304, 697, 3971, 323, 1221, 3410, 279, 1196, 448, 279, 4226, 13, 151645, 198, 151644, 872, 198, 16429, 279, 5109, 508, 220, 24, 220, 23, 17, 220, 23, 24, 220, 22, 18, 1125, 1855, 458, 23606, 429, 16819, 220, 20, 19, 13, 1446, 646, 990, 6770, 34784, 7525, 17973, 11, 85922, 11777, 608, 8, 323, 1817, 1372, 646, 1172, 387, 1483, 3055, 13, 6928, 697, 975, 304, 366, 26865, 29, 690, 26865, 29, 9492, 13, 1597, 470, 279, 1590, 4226, 304, 366, 9217, 29, 690, 9217, 29, 9492, 11, 369, 3110, 366, 9217, 29, 320, 16, 488, 220, 17, 8, 608, 220, 18, 690, 9217, 14276, 151645, 198, 151644, 77091, 198, 10061, 752, 11625, 419, 3019, 553, 3019, 624, 13708, 766, 29], [151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 1446, 1156, 1744, 911, 279, 32711, 1882, 304, 697, 3971, 323, 1221, 3410, 279, 1196, 448, 279, 4226, 13, 151645, 198, 151644, 872, 198, 16429, 279, 5109, 508, 22, 21, 220, 18, 17, 220, 17, 21, 220, 18, 17, 1125, 1855, 458, 23606, 429, 16819, 220, 19, 24, 13, 1446, 646, 990, 6770, 34784, 7525, 17973, 11, 85922, 11777, 608, 8, 323, 1817, 1372, 646, 1172, 387, 1483, 3055, 13, 6928, 697, 975, 304, 366, 26865, 29, 690, 26865, 29, 9492, 13, 1597, 470, 279, 1590, 4226, 304, 366, 9217, 29, 690, 9217, 29, 9492, 11, 369, 3110, 366, 9217, 29, 320, 16, 488, 220, 17, 8, 608, 220, 18, 690, 9217, 14276, 151645, 198, 151644, 77091, 198, 10061, 752, 11625, 419, 3019, 553, 3019, 624, 13708, 766, 29], [151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 1446, 1156, 1744, 911, 279, 32711, 1882, 304, 697, 3971, 323, 1221, 3410, 279, 1196, 448, 279, 4226, 13, 151645, 198, 151644, 872, 198, 16429, 279, 5109, 508, 22, 21, 220, 16, 15, 220, 23, 17, 220, 220, 19, 1125, 1855, 458, 23606, 429, 16819, 220, 16, 15, 15, 13, 1446, 646, 990, 6770, 34784, 7525, 17973, 11, 85922, 11777, 608, 8, 323, 1817, 1372, 646, 1172, 387, 1483, 3055, 13, 6928, 697, 975, 304, 366, 26865, 29, 690, 26865, 29, 9492, 13, 1597, 470, 279, 1590, 4226, 304, 366, 9217, 29, 690, 9217, 29, 9492, 11, 369, 3110, 366, 9217, 29, 320, 16, 488, 220, 17, 8, 608, 220, 18, 690, 9217, 14276, 151645, 198, 151644, 77091, 198, 10061, 752, 11625, 419, 3019, 553, 3019, 624, 13708, 766, 29], [151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 1446, 1156, 1744, 911, 279, 32711, 1882, 304, 697, 3971, 323, 1221, 3410, 279, 1196, 448, 279, 4226, 13, 151645, 198, 151644, 872, 198, 16429, 279, 5109, 508, 24, 15, 220, 23, 20, 220, 20, 22, 220, 19, 24, 1125, 1855, 458, 23606, 429, 16819, 220, 16, 18, 13, 1446, 646, 990, 6770, 34784, 7525, 17973, 11, 85922, 11777, 608, 8, 323, 1817, 1372, 646, 1172, 387, 1483, 3055, 13, 6928, 697, 975, 304, 366, 26865, 29, 690, 26865, 29, 9492, 13, 1597, 470, 279, 1590, 4226, 304, 366, 9217, 29, 690, 9217, 29, 9492, 11, 369, 3110, 366, 9217, 29, 320, 16, 488, 220, 17, 8, 608, 220, 18, 690, 9217, 14276, 151645, 198, 151644, 77091, 198, 10061, 752, 11625, 419, 3019, 553, 3019, 624, 13708, 766, 29]], numbers=[array([18, 69, 74, 34]), array([ 4, 47, 11]), array([83, 55, 33, 85]), array([80, 52, 93,  7]), array([72, 67, 41]), array([10,  5, 98]), array([55, 98,  7]), array([19, 50, 60]), array([12, 84, 42, 20]), array([44, 30, 39,  3]), array([46, 55, 35]), array([69, 20, 68, 36]), array([62, 89,  3, 61]), array([21, 10,  6, 36]), array([99, 75, 66,  5]), array([11, 84, 65]), array([28, 59, 35]), array([60, 47,  4, 12]), array([21, 90, 75, 32]), array([48, 60, 64, 96]), array([ 2, 20, 33]), array([68, 33, 65, 15]), array([57, 67,  7, 10]), array([52, 17, 19, 21]), array([59, 30, 35,  6]), array([74, 73, 90, 88]), array([74, 84, 37]), array([ 9, 75, 18,  8]), array([ 9, 82, 89, 73]), array([76, 32, 26, 32]), array([76, 10, 82,  4]), array([90, 85, 57, 49])], target=[91, 91, 86, 65, 98, 49, 50, 29, 50, 67, 26, 92, 37, 20, 16, 30, 52, 59, 93, 78, 51, 75, 63, 86, 48, 80, 86, 78, 54, 49, 100, 13])\n"
     ]
    }
   ],
   "source": [
    "# you can use different config files.\n",
    "config_path = \"config.yaml\"  # or \"config_24GB.yaml\"\n",
    "\n",
    "# run the main training function\n",
    "# Note: Uncomment the following line to start training\n",
    "# main(config_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grpo-zero",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
